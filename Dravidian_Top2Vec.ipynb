{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div class=\"warning\" style='padding:0.1em; background-color:#E9D8FD; color:#69337A'>\n<span>\n<p style='margin-top:1em; text-align:center'>\n<p style='margin-left:1em;'>\n\n# Table of Contents <a class=\"anchor\"  id=\"TOC\"></a>\n* [Installations](#installations)\n* [Import Libraries](#importlib)\n* [Tokenizers](#tokenizers)\n    * [Autotokenizer](#autotokenizer)\n        * [Muril Large Cased](#murillarge)\n        * [Muril Base Cased](#murilbase)\n        * [Indic BERT](#indicbert)\n        * [Opus-mt-en-dra](#opus)\n* [Custom Tokenizer Function](#customtoken)\n* [Top2Vec](#top2vec)\n* [Top2Vec in Tamil](#top2vec-tamil)\n    * [Load Data](#loaddata)\n    * [Parameters](#parameters)\n        * [Embedding Model Paths](#embeddingmodels)\n        * [UMAP and HDBSCAN parameters](#umaphdbscan)    \n    * [Getting Topic Vectors](#topicveccall)\n  \n</p>\n<p style='margin-bottom:1em; margin-right:1em; text-align:right; font-family:Georgia'> \n</p></span>\n</div>","metadata":{}},{"cell_type":"markdown","source":"# Installations <a class=\"anchor\"  id=\"installations\"></a>\n[Go Back to Table of Contents](#TOC)","metadata":{}},{"cell_type":"code","source":"!pip uninstall umap\n!pip install umap-learn\n!pip install gensim==4.2.0\n!pip install joblib==1.1.0\n# !pip install sentencepiece\n!pip install hdbscan\n!pip install transformers\n!pip install -U sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2022-12-07T15:19:21.600820Z","iopub.execute_input":"2022-12-07T15:19:21.601315Z","iopub.status.idle":"2022-12-07T15:21:37.153258Z","shell.execute_reply.started":"2022-12-07T15:19:21.601225Z","shell.execute_reply":"2022-12-07T15:21:37.151507Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping umap as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: umap-learn in /opt/conda/lib/python3.7/site-packages (0.5.3)\nRequirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.7/site-packages (from umap-learn) (1.7.3)\nRequirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.7/site-packages (from umap-learn) (1.0.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from umap-learn) (1.21.6)\nRequirement already satisfied: pynndescent>=0.5 in /opt/conda/lib/python3.7/site-packages (from umap-learn) (0.5.7)\nRequirement already satisfied: numba>=0.49 in /opt/conda/lib/python3.7/site-packages (from umap-learn) (0.55.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from umap-learn) (4.64.0)\nRequirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba>=0.49->umap-learn) (0.38.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.49->umap-learn) (59.8.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from pynndescent>=0.5->umap-learn) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting gensim==4.2.0\n  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from gensim==4.2.0) (1.21.6)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim==4.2.0) (5.2.1)\nRequirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim==4.2.0) (1.7.3)\nInstalling collected packages: gensim\n  Attempting uninstall: gensim\n    Found existing installation: gensim 4.0.1\n    Uninstalling gensim-4.0.1:\n      Successfully uninstalled gensim-4.0.1\nSuccessfully installed gensim-4.2.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting joblib==1.1.0\n  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: joblib\n  Attempting uninstall: joblib\n    Found existing installation: joblib 1.0.1\n    Uninstalling joblib-1.0.1:\n      Successfully uninstalled joblib-1.0.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.5.3 which is incompatible.\npandas-profiling 3.1.0 requires joblib~=1.0.1, but you have joblib 1.1.0 which is incompatible.\npandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\nallennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed joblib-1.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting hdbscan\n  Downloading hdbscan-0.8.29.tar.gz (5.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from hdbscan) (1.21.6)\nRequirement already satisfied: cython>=0.27 in /opt/conda/lib/python3.7/site-packages (from hdbscan) (0.29.32)\nRequirement already satisfied: scikit-learn>=0.20 in /opt/conda/lib/python3.7/site-packages (from hdbscan) (1.0.2)\nRequirement already satisfied: joblib>=1.0 in /opt/conda/lib/python3.7/site-packages (from hdbscan) (1.1.0)\nRequirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.7/site-packages (from hdbscan) (1.7.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20->hdbscan) (3.1.0)\nBuilding wheels for collected packages: hdbscan\n  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for hdbscan: filename=hdbscan-0.8.29-cp37-cp37m-linux_x86_64.whl size=3426392 sha256=43594ad4fe6168ec95cfd0b5c385145e1647d90108850c3c39f39c56f3562675\n  Stored in directory: /root/.cache/pip/wheels/93/78/2e/03ee191669a772e9653260aa3bd53e0b1a768751a9676e8c82\nSuccessfully built hdbscan\nInstalling collected packages: hdbscan\nSuccessfully installed hdbscan-0.8.29\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.8.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.6.15.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.20.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.64.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.11.0+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.12.0+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.21.6)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.0.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.7.3)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (3.7)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.1.97)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.8.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.12.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.7.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.1.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (8.0.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers) (9.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.6.15.2)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=f31168cb626d79ae8d37efc89ddca79f702c617b43cbecae0de2fb0538a7ce70\n  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import Libraries <a class=\"anchor\"  id=\"importlib\"></a>\n[Go Back to Table of Contents](#TOC)","metadata":{}},{"cell_type":"code","source":"import logging\nimport numpy as np\nimport pandas as pd\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\nfrom gensim.utils import simple_preprocess\nfrom gensim.parsing.preprocessing import strip_tags, strip_punctuation\nfrom gensim.models.phrases import Phrases\nimport umap.umap_ as umap\nimport hdbscan\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nfrom joblib import dump, load\nfrom sklearn.cluster import dbscan\nimport tempfile\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import normalize\nfrom scipy.special import softmax\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModel\nfrom sentence_transformers import SentenceTransformer\n\ntry:\n    import hnswlib\n\n    _HAVE_HNSWLIB = True\nexcept ImportError:\n    _HAVE_HNSWLIB = False\n\ntry:\n    import tensorflow as tf\n    import tensorflow_hub as hub\n    import tensorflow_text\n\n    _HAVE_TENSORFLOW = True\nexcept ImportError:\n    _HAVE_TENSORFLOW = False\n\ntry:\n    from sentence_transformers import SentenceTransformer\n\n    _HAVE_TORCH = True\nexcept ImportError:\n    _HAVE_TORCH = False\n\nlogger = logging.getLogger('top2vec')\nlogger.setLevel(logging.WARNING)\nsh = logging.StreamHandler()\nsh.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\nlogger.addHandler(sh)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T15:21:37.155423Z","iopub.execute_input":"2022-12-07T15:21:37.155806Z","iopub.status.idle":"2022-12-07T15:22:00.390303Z","shell.execute_reply.started":"2022-12-07T15:21:37.155771Z","shell.execute_reply":"2022-12-07T15:22:00.388620Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Tokenizers <a class=\"anchor\"  id=\"tokenizers\"></a>\n[Go Back to Table of Contents](#TOC)","metadata":{}},{"cell_type":"markdown","source":"### Autotokenizer <a class=\"anchor\"  id=\"autotokenizer\"></a>\n[Go Back to Table of Contents](#TOC)","metadata":{}},{"cell_type":"markdown","source":"#### Muril Base Cased <a class=\"anchor\"  id=\"murilbase\"></a>\n[Go Back to Table of Contents](#TOC)","metadata":{}},{"cell_type":"code","source":"# tokenizer1 = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")","metadata":{"execution":{"iopub.status.busy":"2022-11-03T08:57:47.743849Z","iopub.execute_input":"2022-11-03T08:57:47.745166Z","iopub.status.idle":"2022-11-03T08:58:03.090251Z","shell.execute_reply.started":"2022-11-03T08:57:47.745117Z","shell.execute_reply":"2022-11-03T08:58:03.089192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Muril Large Cased <a class=\"anchor\"  id=\"murillarge\"></a>\n[Go Back to Table of Contents](#TOC)","metadata":{}},{"cell_type":"code","source":"tokenizer1 = AutoTokenizer.from_pretrained(\"google/muril-large-cased\")","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:37:08.150484Z","iopub.execute_input":"2022-12-07T16:37:08.150879Z","iopub.status.idle":"2022-12-07T16:37:10.406452Z","shell.execute_reply.started":"2022-12-07T16:37:08.150820Z","shell.execute_reply":"2022-12-07T16:37:10.405356Z"},"trusted":true},"execution_count":85,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/181 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16084c1ba2e547e1999b438a509bb83c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/406 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e661d47b458c4093901a2781a939c490"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/3.02M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fad10b74fa0c4c6585f13ae5f839cb58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50403eb77ba24bd38880f34af8989676"}},"metadata":{}}]},{"cell_type":"markdown","source":"#### Indic Bert <a class=\"anchor\"  id=\"indicbert\"></a>\n[Go Back to Table of Contents](#TOC)","metadata":{}},{"cell_type":"code","source":"# tokenizer1 = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")","metadata":{"execution":{"iopub.status.busy":"2022-11-03T09:17:25.508248Z","iopub.execute_input":"2022-11-03T09:17:25.508684Z","iopub.status.idle":"2022-11-03T09:17:37.109718Z","shell.execute_reply.started":"2022-11-03T09:17:25.508652Z","shell.execute_reply":"2022-11-03T09:17:37.107245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Opus-mt-en-dra <a class=\"anchor\"  id=\"opus\"></a>\n[Go Back to Table of Contents](#TOC)","metadata":{}},{"cell_type":"code","source":"# tokenizer1 = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-dra\")","metadata":{"execution":{"iopub.status.busy":"2022-11-03T09:13:36.668983Z","iopub.execute_input":"2022-11-03T09:13:36.669420Z","iopub.status.idle":"2022-11-03T09:13:46.460946Z","shell.execute_reply.started":"2022-11-03T09:13:36.669382Z","shell.execute_reply":"2022-11-03T09:13:46.460010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom Tokenizer <a class=\"anchor\"  id=\"customtoken\"></a>\n[Go Back to Table of Contents](#TOC)","metadata":{}},{"cell_type":"code","source":"def custom_tokenizer(d):\n    \"\"\"Tokenize a document for training and remove too long/short words\n\n    Parameters\n    ----------\n    document: List of str\n        Input document.\n\n    Returns\n    -------\n    tokenized_document: List of str\n        List of tokens.\n\n    \"\"\"\n    tokens_list = []\n    encoding = tokenizer1.encode(strip_punctuation(d))\n    tokens = tokenizer1.convert_ids_to_tokens(encoding)\n    # tokens_list.append(tokens[1:-1])\n    results = []\n    oldx = None\n    for x in tokens[1:-1]:\n        if x.startswith('#'):\n            y = x.replace('#', '')\n            # results.append(oldx+y)\n            oldx = oldx+y\n        else:\n            if oldx == None:\n                results.append(x)\n            else:\n                results.append(oldx)\n            oldx = x\n    return results","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:37:15.549439Z","iopub.execute_input":"2022-12-07T16:37:15.551219Z","iopub.status.idle":"2022-12-07T16:37:15.558727Z","shell.execute_reply.started":"2022-12-07T16:37:15.551161Z","shell.execute_reply":"2022-12-07T16:37:15.557276Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":"# Top2Vec <a class=\"anchor\"  id=\"top2vec\"></a>\n[Go Back to Table of Contents](#TOC)","metadata":{}},{"cell_type":"code","source":"def default_tokenizer(document):\n    \"\"\"Tokenize a document for training and remove too long/short words\n    Parameters\n    ----------\n    document: List of str\n        Input document.\n    Returns\n    -------\n    tokenized_document: List of str\n        List of tokens.\n    \"\"\"\n    return simple_preprocess(strip_tags(document), deacc=True)\n\n\ndef get_chunks(tokens, chunk_length, max_num_chunks, chunk_overlap_ratio):\n    \"\"\"Split a document into sequential chunks\n    Parameters\n    ----------\n    tokens: List of str\n        Input document tokens.\n    chunk_length: int\n        Length of each document chunk.\n    max_num_chunks: int (Optional, default None)\n        Limit the number of document chunks\n    chunk_overlap_ratio: float\n        Fraction of overlapping tokens between sequential chunks.\n    Returns\n    -------\n    chunked_document: List of str\n        List of document chunks.\n    \"\"\"\n    num_tokens = len(tokens)\n    if num_tokens == 0:\n        return [\"\"]\n\n    num_chunks = int(np.ceil(num_tokens / chunk_length))\n\n    if max_num_chunks is not None:\n        num_chunks = min(num_chunks, max_num_chunks)\n\n    return [\" \".join(tokens[i:i + chunk_length])\n            for i in list(range(0, num_tokens, int(chunk_length * (1 - chunk_overlap_ratio))))[0:num_chunks]]\n\n\ndef get_random_chunks(tokens, chunk_length, chunk_len_coverage_ratio, max_num_chunks):\n    \"\"\"Split a document into chunks starting at random positions\n    Parameters\n    ----------\n    tokens: List of str\n        Input document tokens.\n    chunk_length: int\n        Length of each document chunk.\n    chunk_len_coverage_ratio: float\n        Proportion of token length that will be covered by chunks. Default\n        value of 1.0 means chunk lengths will add up to number of tokens.\n        This does not mean all tokens will be covered.\n    max_num_chunks: int (Optional, default None)\n        Limit the number of document chunks\n    Returns\n    -------\n    chunked_document: List of str\n        List of document chunks.\n    \"\"\"\n    num_tokens = len(tokens)\n    if num_tokens == 0:\n        return [\"\"]\n\n    num_chunks = int(np.ceil(num_tokens * chunk_len_coverage_ratio / chunk_length))\n\n    if max_num_chunks is not None:\n        num_chunks = min(num_chunks, max_num_chunks)\n\n    starts = np.random.choice(range(0, num_tokens), size=num_chunks)\n    return [\" \".join(tokens[i:i + chunk_length]) for i in starts]\n\n\nclass Top2Vec:\n    \"\"\"\n    Top2Vec\n    Creates jointly embedded topic, document and word vectors.\n    Parameters\n    ----------\n    documents: List of str\n        Input corpus, should be a list of strings.\n    min_count: int (Optional, default 50)\n        Ignores all words with total frequency lower than this. For smaller\n        corpora a smaller min_count will be necessary.\n    ngram_vocab: bool (Optional, default False)\n        Add phrases to topic descriptions.\n        Uses gensim phrases to find common phrases in the corpus and adds them\n        to the vocabulary.\n        For more information visit:\n        https://radimrehurek.com/gensim/models/phrases.html\n    ngram_vocab_args: dict (Optional, default None)\n        Pass custom arguments to gensim phrases.\n        For more information visit:\n        https://radimrehurek.com/gensim/models/phrases.html\n    embedding_model: string or callable\n        This will determine which model is used to generate the document and\n        word embeddings. The valid string options are:\n            * doc2vec\n            * universal-sentence-encoder\n            * universal-sentence-encoder-large\n            * universal-sentence-encoder-multilingual\n            * universal-sentence-encoder-multilingual-large\n            * distiluse-base-multilingual-cased\n            * all-MiniLM-L6-v2\n            * paraphrase-multilingual-MiniLM-L12-v2\n        For large data sets and data sets with very unique vocabulary doc2vec\n        could produce better results. This will train a doc2vec model from\n        scratch. This method is language agnostic. However multiple languages\n        will not be aligned.\n        Using the universal sentence encoder options will be much faster since\n        those are pre-trained and efficient models. The universal sentence\n        encoder options are suggested for smaller data sets. They are also\n        good options for large data sets that are in English or in languages\n        covered by the multilingual model. It is also suggested for data sets\n        that are multilingual.\n        For more information on universal-sentence-encoder options visit:\n        https://tfhub.dev/google/collections/universal-sentence-encoder/1\n        The SBERT pre-trained sentence transformer options are\n        distiluse-base-multilingual-cased,\n        paraphrase-multilingual-MiniLM-L12-v2, and all-MiniLM-L6-v2.\n        The distiluse-base-multilingual-cased and\n        paraphrase-multilingual-MiniLM-L12-v2 are suggested for multilingual\n        datasets and languages that are not\n        covered by the multilingual universal sentence encoder. The\n        transformer is significantly slower than the universal sentence\n        encoder options(except for the large options).\n        For more information on SBERT options visit:\n        https://www.sbert.net/docs/pretrained_models.html\n        If passing a callable embedding_model note that it will not be saved\n        when saving a top2vec model. After loading such a saved top2vec model\n        the set_embedding_model method will need to be called and the same\n        embedding_model callable used during training must be passed to it.\n    embedding_model_path: string (Optional)\n        Pre-trained embedding models will be downloaded automatically by\n        default. However they can also be uploaded from a file that is in the\n        location of embedding_model_path.\n        Warning: the model at embedding_model_path must match the\n        embedding_model parameter type.\n    embedding_batch_size: int (default=32)\n        Batch size for documents being embedded.\n    split_documents: bool (default False)\n        If set to True, documents will be split into parts before embedding.\n        After embedding the multiple document part embeddings will be averaged\n        to create a single embedding per document. This is useful when documents\n        are very large or when the embedding model has a token limit.\n        Document chunking or a senticizer can be used for document splitting.\n    document_chunker: string or callable (default 'sequential')\n        This will break the document into chunks. The valid string options are:\n            * sequential\n            * random\n        The sequential chunker will split the document into chunks of specified\n        length and ratio of overlap. This is the recommended method.\n        The random chunking option will take random chunks of specified length\n        from the document. These can overlap and should be thought of as\n        sampling chunks with replacement from the document.\n        If a callable is passed it must take as input a list of tokens of\n        a document and return a list of strings representing the resulting\n        document chunks.\n        Only one of document_chunker or sentincizer should be used.\n    chunk_length: int (default 100)\n        The number of tokens per document chunk if using the document chunker\n        string options.\n    max_num_chunks: int (Optional)\n        The maximum number of chunks generated per document if using the\n        document chunker string options.\n    chunk_overlap_ratio: float (default 0.5)\n        Only applies to the 'sequential' document chunker.\n        Fraction of overlapping tokens between sequential chunks. A value of\n        0 will result i no overlap, where as 0.5 will overlap half of the\n        previous chunk.\n    chunk_len_coverage_ratio: float (default 1.0)\n        Only applies to the 'random' document chunker option.\n        Proportion of token length that will be covered by chunks. Default\n        value of 1.0 means chunk lengths will add up to number of tokens of\n        the document. This does not mean all tokens will be covered since\n        chunks can be overlapping.\n    sentencizer: callable (Optional)\n        A sentincizer callable can be passed. The input should be a string\n        representing the document and the output should be a list of strings\n        representing the document sentence chunks.\n        Only one of document_chunker or sentincizer should be used.\n    speed: string (Optional, default 'learn')\n        This parameter is only used when using doc2vec as embedding_model.\n        It will determine how fast the model takes to train. The\n        fast-learn option is the fastest and will generate the lowest quality\n        vectors. The learn option will learn better quality vectors but take\n        a longer time to train. The deep-learn option will learn the best\n        quality vectors but will take significant time to train. The valid\n        string speed options are:\n        \n            * fast-learn\n            * learn\n            * deep-learn\n    use_corpus_file: bool (Optional, default False)\n        This parameter is only used when using doc2vec as embedding_model.\n        Setting use_corpus_file to True can sometimes provide speedup for\n        large datasets when multiple worker threads are available. Documents\n        are still passed to the model as a list of str, the model will create\n        a temporary corpus file for training.\n    document_ids: List of str, int (Optional)\n        A unique value per document that will be used for referring to\n        documents in search results. If ids are not given to the model, the\n        index of each document in the original corpus will become the id.\n    keep_documents: bool (Optional, default True)\n        If set to False documents will only be used for training and not saved\n        as part of the model. This will reduce model size. When using search\n        functions only document ids will be returned, not the actual\n        documents.\n    workers: int (Optional)\n        The amount of worker threads to be used in training the model. Larger\n        amount will lead to faster training.\n    \n    tokenizer: callable (Optional, default None)\n        Override the default tokenization method. If None then\n        gensim.utils.simple_preprocess will be used.\n        Tokenizer must take a document and return a list of tokens.\n    use_embedding_model_tokenizer: bool (Optional, default False)\n        If using an embedding model other than doc2vec, use the model's\n        tokenizer for document embedding. If set to True the tokenizer, either\n        default or passed callable will be used to tokenize the text to\n        extract the vocabulary for word embedding.\n    umap_args: dict (Optional, default None)\n        Pass custom arguments to UMAP.\n    hdbscan_args: dict (Optional, default None)\n        Pass custom arguments to HDBSCAN.\n    \n    verbose: bool (Optional, default True)\n        Whether to print status data during training.\n    \"\"\"\n\n    def __init__(self,\n                 documents,\n                 min_count=50,\n                 ngram_vocab=False,\n                 ngram_vocab_args=None,\n                 embedding_model='doc2vec',\n                 embedding_model_path=None,\n                 embedding_batch_size=32,\n                 split_documents=False,\n                 document_chunker='sequential',\n                 chunk_length=100,\n                 max_num_chunks=None,\n                 chunk_overlap_ratio=0.5,\n                 chunk_len_coverage_ratio=1.0,\n                 sentencizer=None,\n                 speed='learn',\n                 use_corpus_file=False,\n                 document_ids=None,\n                 keep_documents=True,\n                 workers=None,\n                 tokenizer=None,\n                 use_embedding_model_tokenizer=False,\n                 umap_args=None,\n                 hdbscan_args=None,\n                 verbose=True\n                 ):\n\n        if verbose:\n            logger.setLevel(logging.DEBUG)\n            self.verbose = True\n        else:\n            logger.setLevel(logging.WARNING)\n            self.verbose = False\n\n        if tokenizer is None:\n            tokenizer = default_tokenizer\n\n        # validate documents\n        if not (isinstance(documents, list) or isinstance(documents, np.ndarray)):\n            raise ValueError(\"Documents need to be a list of strings\")\n        if not all((isinstance(doc, str) or isinstance(doc, np.str_)) for doc in documents):\n            raise ValueError(\"Documents need to be a list of strings\")\n        if keep_documents:\n            self.documents = np.array(documents, dtype=\"object\")\n        else:\n            self.documents = None\n\n        # validate document ids\n        if document_ids is not None:\n            if not (isinstance(document_ids, list) or isinstance(document_ids, np.ndarray)):\n                raise ValueError(\"Documents ids need to be a list of str or int\")\n\n            if len(documents) != len(document_ids):\n                raise ValueError(\"Document ids need to match number of documents\")\n            elif len(document_ids) != len(set(document_ids)):\n                raise ValueError(\"Document ids need to be unique\")\n\n            if all((isinstance(doc_id, str) or isinstance(doc_id, np.str_)) for doc_id in document_ids):\n                self.doc_id_type = np.str_\n            elif all((isinstance(doc_id, int) or isinstance(doc_id, np.int_)) for doc_id in document_ids):\n                self.doc_id_type = np.int_\n            else:\n                raise ValueError(\"Document ids need to be str or int\")\n\n            self.document_ids_provided = True\n            self.document_ids = np.array(document_ids)\n            self.doc_id2index = dict(zip(document_ids, list(range(0, len(document_ids)))))\n        else:\n            self.document_ids_provided = False\n            self.document_ids = np.array(range(0, len(documents)))\n            self.doc_id2index = dict(zip(self.document_ids, list(range(0, len(self.document_ids)))))\n            self.doc_id_type = np.int_\n\n        self.embedding_model_path = embedding_model_path\n\n        # validate document splitting\n        use_sentencizer = False\n        custom_chunker = False\n        if split_documents:\n            if document_chunker == 'sequential':\n                document_chunker = get_chunks\n                document_chunker_args = {\"chunk_length\": chunk_length,\n                                         \"max_num_chunks\": max_num_chunks,\n                                         \"chunk_overlap_ratio\": chunk_overlap_ratio}\n\n            elif document_chunker == 'random':\n                document_chunker = get_random_chunks\n                document_chunker_args = {\"chunk_length\": chunk_length,\n                                         \"max_num_chunks\": max_num_chunks,\n                                         \"chunk_len_coverage_ratio\": chunk_len_coverage_ratio}\n\n            elif callable(document_chunker):\n                custom_chunker = True\n            elif sentencizer is None:\n                raise ValueError(f\"{document_chunker} is an invalid document chunker.\")\n            elif callable(sentencizer):\n                use_sentencizer = True\n            else:\n                raise ValueError(f\"{sentencizer} is invalid. Document sentencizer must be callable.\")\n\n        if embedding_model == 'doc2vec':\n\n            # validate training inputs\n            if speed == \"fast-learn\":\n                hs = 0\n                negative = 5\n                epochs = 40\n            elif speed == \"learn\":\n                hs = 1\n                negative = 0\n                epochs = 40\n            elif speed == \"deep-learn\":\n                hs = 1\n                negative = 0\n                epochs = 400\n            elif speed == \"test-learn\":\n                hs = 0\n                negative = 5\n                epochs = 1\n            else:\n                raise ValueError(\"speed parameter needs to be one of: fast-learn, learn or deep-learn\")\n\n            if workers is None:\n                pass\n            elif isinstance(workers, int):\n                pass\n            else:\n                raise ValueError(\"workers needs to be an int\")\n\n            doc2vec_args = {\"vector_size\": 300,\n                            \"min_count\": min_count,\n                            \"window\": 15,\n                            \"sample\": 1e-5,\n                            \"negative\": negative,\n                            \"hs\": hs,\n                            \"epochs\": epochs,\n                            \"dm\": 0,\n                            \"dbow_words\": 1}\n\n            if workers is not None:\n                doc2vec_args[\"workers\"] = workers\n\n            logger.info('Pre-processing documents for training')\n\n            if use_corpus_file:\n                processed = [' '.join(tokenizer(doc)) for doc in documents]\n                lines = \"\\n\".join(processed)\n                temp = tempfile.NamedTemporaryFile(mode='w+t')\n                temp.write(lines)\n                doc2vec_args[\"corpus_file\"] = temp.name\n\n            else:\n                train_corpus = [TaggedDocument(tokenizer(doc), [i]) for i, doc in enumerate(documents)]\n                doc2vec_args[\"documents\"] = train_corpus\n\n            logger.info('Creating joint document/word embedding')\n            self.embedding_model = 'doc2vec'\n            self.model = Doc2Vec(**doc2vec_args)\n\n            self.word_vectors = self.model.wv.get_normed_vectors()\n            self.word_indexes = self.model.wv.key_to_index\n            self.vocab = list(self.model.wv.key_to_index.keys())\n            self.document_vectors = self.model.dv.get_normed_vectors()\n\n            if ngram_vocab:\n                tokenized_corpus = [tokenizer(doc) for doc in documents]\n\n                if ngram_vocab_args is None:\n                    ngram_vocab_args = {'sentences': tokenized_corpus,\n                                        'min_count': 5,\n                                        'threshold': 10.0,\n                                        'delimiter': ' '}\n                else:\n                    ngram_vocab_args['sentences'] = tokenized_corpus\n                    ngram_vocab_args['delimiter'] = ' '\n\n                phrase_model = Phrases(**ngram_vocab_args)\n                phrase_results = phrase_model.find_phrases(tokenized_corpus)\n                phrases = list(phrase_results.keys())\n\n                phrases_processed = [tokenizer(phrase) for phrase in phrases]\n                phrase_vectors = np.vstack([self.model.infer_vector(doc_words=phrase,\n                                                                    alpha=0.025,\n                                                                    min_alpha=0.01,\n                                                                    epochs=100) for phrase in phrases_processed])\n                phrase_vectors = self._l2_normalize(phrase_vectors)\n\n                self.word_vectors = np.vstack([self.word_vectors, phrase_vectors])\n                self.vocab = self.vocab + phrases\n                self.word_indexes = dict(zip(self.vocab, range(len(self.vocab))))\n\n            if use_corpus_file:\n                temp.close()\n\n        elif (embedding_model in acceptable_embedding_models) or callable(embedding_model):\n\n            self.embed = None\n            self.embedding_model = embedding_model\n\n            self._check_import_status()\n\n            logger.info('Pre-processing documents for training')\n\n            # preprocess documents\n            tokenized_corpus = [tokenizer(doc) for doc in documents]\n\n            def return_doc(doc):\n                return doc\n\n            # preprocess vocabulary\n            vectorizer = CountVectorizer(tokenizer=return_doc, preprocessor=return_doc)\n            doc_word_counts = vectorizer.fit_transform(tokenized_corpus)\n            words = vectorizer.get_feature_names()\n            word_counts = np.array(np.sum(doc_word_counts, axis=0).tolist()[0])\n            vocab_inds = np.where(word_counts > min_count)[0]\n\n            if len(vocab_inds) == 0:\n                raise ValueError(f\"A min_count of {min_count} results in \"\n                                 f\"all words being ignored, choose a lower value.\")\n            self.vocab = [words[ind] for ind in vocab_inds]\n\n            if ngram_vocab:\n                if ngram_vocab_args is None:\n                    ngram_vocab_args = {'sentences': tokenized_corpus,\n                                        'min_count': 5,\n                                        'threshold': 10.0,\n                                        'delimiter': ' '}\n                else:\n                    ngram_vocab_args['sentences'] = tokenized_corpus\n                    ngram_vocab_args['delimiter'] = ' '\n\n                phrase_model = Phrases(**ngram_vocab_args)\n                phrase_results = phrase_model.find_phrases(tokenized_corpus)\n                phrases = list(phrase_results.keys())\n\n                self.vocab = self.vocab + phrases\n\n            self._check_model_status()\n\n            logger.info('Creating joint document/word embedding')\n\n            # embed words\n            self.word_indexes = dict(zip(self.vocab, range(len(self.vocab))))\n            self.word_vectors = self._l2_normalize(np.array(self.embed(self.vocab)))\n\n            # embed documents\n\n            # split documents\n            if split_documents:\n                if use_sentencizer:\n                    chunk_id = 0\n                    chunked_docs = []\n                    chunked_doc_ids = []\n                    for doc in documents:\n                        doc_chunks = sentencizer(doc)\n                        doc_chunk_ids = [chunk_id] * len(doc_chunks)\n                        chunk_id += 1\n                        chunked_docs.extend(doc_chunks)\n                        chunked_doc_ids.extend(doc_chunk_ids)\n\n                else:\n                    chunk_id = 0\n                    chunked_docs = []\n                    chunked_doc_ids = []\n                    for tokens in tokenized_corpus:\n                        if custom_chunker:\n                            doc_chunks = document_chunker(tokens)\n                        else:\n                            doc_chunks = document_chunker(tokens, **document_chunker_args)\n                        doc_chunk_ids = [chunk_id] * len(doc_chunks)\n                        chunk_id += 1\n                        chunked_docs.extend(doc_chunks)\n                        chunked_doc_ids.extend(doc_chunk_ids)\n\n                chunked_doc_ids = np.array(chunked_doc_ids)\n                document_chunk_vectors = self._embed_documents(chunked_docs, embedding_batch_size)\n                self.document_vectors = self._l2_normalize(\n                    np.vstack([document_chunk_vectors[np.where(chunked_doc_ids == label)[0]]\n                              .mean(axis=0) for label in set(chunked_doc_ids)]))\n\n            # original documents\n            else:\n                if use_embedding_model_tokenizer:\n                    self.document_vectors = self._embed_documents(documents, embedding_batch_size)\n                else:\n                    train_corpus = [' '.join(tokens) for tokens in tokenized_corpus]\n                    self.document_vectors = self._embed_documents(train_corpus, embedding_batch_size)\n\n        else:\n            raise ValueError(f\"{embedding_model} is an invalid embedding model.\")\n\n        # create 5D embeddings of documents\n        logger.info('Creating lower dimension embedding of documents')\n\n        if umap_args is None:\n            umap_args = {'n_neighbors': 15,\n                         'n_components': 5,\n                         'metric': 'cosine'}\n\n        umap_model = umap.UMAP(**umap_args).fit(self.document_vectors)\n\n        # find dense areas of document vectors\n        logger.info('Finding dense areas of documents')\n\n        if hdbscan_args is None:\n            hdbscan_args = {'min_cluster_size': 15,\n                            'metric': 'euclidean',\n                            'cluster_selection_method': 'eom'}\n\n        cluster = hdbscan.HDBSCAN(**hdbscan_args).fit(umap_model.embedding_)\n\n        # calculate topic vectors from dense areas of documents\n        logger.info('Finding topics')\n\n        # create topic vectors\n        self._create_topic_vectors(cluster.labels_)\n\n        # deduplicate topics\n        self._deduplicate_topics()\n\n        # find topic words and scores\n        self.topic_words, self.topic_word_scores = self._find_topic_words_and_scores(topic_vectors=self.topic_vectors)\n\n        # assign documents to topic\n        self.doc_top, self.doc_dist = self._calculate_documents_topic(self.topic_vectors,\n                                                                      self.document_vectors)\n\n        # calculate topic sizes\n        self.topic_sizes = self._calculate_topic_sizes(hierarchy=False)\n\n        # re-order topics\n        self._reorder_topics(hierarchy=False)\n\n        # initialize variables for hierarchical topic reduction\n        self.topic_vectors_reduced = None\n        self.doc_top_reduced = None\n        self.doc_dist_reduced = None\n        self.topic_sizes_reduced = None\n        self.topic_words_reduced = None\n        self.topic_word_scores_reduced = None\n        self.hierarchy = None\n\n        # initialize document indexing variables\n        self.document_index = None\n        self.serialized_document_index = None\n        self.documents_indexed = False\n        self.index_id2doc_id = None\n        self.doc_id2index_id = None\n\n        # initialize word indexing variables\n        self.word_index = None\n        self.serialized_word_index = None\n        self.words_indexed = False\n\n    def save(self, file):\n        \"\"\"\n        Saves the current model to the specified file.\n        Parameters\n        ----------\n        file: str\n            File where model will be saved.\n        \"\"\"\n\n        document_index_temp = None\n        word_index_temp = None\n\n        # do not save sentence encoders, sentence transformers and custom embedding\n        if self.embedding_model not in [\"doc2vec\"]:\n            self.embed = None\n\n        # serialize document index so that it can be saved\n        if self.documents_indexed:\n            temp = tempfile.NamedTemporaryFile(mode='w+b')\n            self.document_index.save_index(temp.name)\n            self.serialized_document_index = temp.read()\n            temp.close()\n            document_index_temp = self.document_index\n            self.document_index = None\n\n        # serialize word index so that it can be saved\n        if self.words_indexed:\n            temp = tempfile.NamedTemporaryFile(mode='w+b')\n            self.word_index.save_index(temp.name)\n            self.serialized_word_index = temp.read()\n            temp.close()\n            word_index_temp = self.word_index\n            self.word_index = None\n\n        dump(self, file)\n\n        self.document_index = document_index_temp\n        self.word_index = word_index_temp\n\n    @classmethod\n    def load(cls, file):\n        \"\"\"\n        Load a pre-trained model from the specified file.\n        Parameters\n        ----------\n        file: str\n            File where model will be loaded from.\n        \"\"\"\n\n        top2vec_model = load(file)\n\n        # load document index\n        if top2vec_model.documents_indexed:\n            if not _HAVE_HNSWLIB:\n                raise ImportError(f\"Cannot load document index.\\n\\n\"\n                                  \"Try: pip install top2vec[indexing]\\n\\n\"\n                                  \"Alternatively try: pip install hnswlib\")\n\n            temp = tempfile.NamedTemporaryFile(mode='w+b')\n            temp.write(top2vec_model.serialized_document_index)\n            document_vectors = top2vec_model.document_vectors\n            top2vec_model.document_index = hnswlib.Index(space='ip',\n                                                         dim=document_vectors.shape[1])\n            top2vec_model.document_index.load_index(temp.name, max_elements=document_vectors.shape[0])\n            temp.close()\n            top2vec_model.serialized_document_index = None\n\n        # load word index\n        if top2vec_model.words_indexed:\n\n            if not _HAVE_HNSWLIB:\n                raise ImportError(f\"Cannot load word index.\\n\\n\"\n                                  \"Try: pip install top2vec[indexing]\\n\\n\"\n                                  \"Alternatively try: pip install hnswlib\")\n\n            temp = tempfile.NamedTemporaryFile(mode='w+b')\n            temp.write(top2vec_model.serialized_word_index)\n            word_vectors = top2vec_model.word_vectors\n            top2vec_model.word_index = hnswlib.Index(space='ip',\n                                                     dim=word_vectors.shape[1])\n            top2vec_model.word_index.load_index(temp.name, max_elements=word_vectors.shape[0])\n            temp.close()\n            top2vec_model.serialized_word_index = None\n\n        return top2vec_model\n\n    @staticmethod\n    def _l2_normalize(vectors):\n\n        if vectors.ndim == 2:\n            return normalize(vectors)\n        else:\n            return normalize(vectors.reshape(1, -1))[0]\n\n    def _embed_documents(self, train_corpus, batch_size):\n\n        self._check_import_status()\n        self._check_model_status()\n\n        # embed documents\n        document_vectors = []\n\n        if (self.embedding_model in use_models) or self.embedding_model == \"custom\":\n\n            current = 0\n            batches = int(len(train_corpus) / batch_size)\n            extra = len(train_corpus) % batch_size\n\n            for ind in range(0, batches):\n                document_vectors.append(self.embed(train_corpus[current:current + batch_size]))\n                current += batch_size\n\n            if extra > 0:\n                document_vectors.append(self.embed(train_corpus[current:current + extra]))\n\n            document_vectors = self._l2_normalize(np.array(np.vstack(document_vectors)))\n\n        else:\n            document_vectors = self.embed(train_corpus, batch_size=batch_size)\n\n        return document_vectors\n\n    def _embed_query(self, query):\n        self._check_import_status()\n        self._check_model_status()\n\n        return self._l2_normalize(np.array(self.embed([query])[0]))\n\n    def _create_topic_vectors(self, cluster_labels):\n        unique_labels = set(cluster_labels)\n        if -1 in unique_labels:\n            unique_labels.remove(-1)\n        self.topic_vectors = self._l2_normalize(\n            np.vstack([self.document_vectors[np.where(cluster_labels == label)[0]]\n                      .mean(axis=0) for label in unique_labels]))\n\n    def _deduplicate_topics(self):\n        core_samples, labels = dbscan(X=self.topic_vectors,\n                                      eps=0.1,\n                                      min_samples=2,\n                                      metric=\"cosine\")\n\n        duplicate_clusters = set(labels)\n\n        if len(duplicate_clusters) > 1 or -1 not in duplicate_clusters:\n\n            # unique topics\n            unique_topics = self.topic_vectors[np.where(labels == -1)[0]]\n\n            if -1 in duplicate_clusters:\n                duplicate_clusters.remove(-1)\n\n            # merge duplicate topics\n            for unique_label in duplicate_clusters:\n                unique_topics = np.vstack(\n                    [unique_topics, self._l2_normalize(self.topic_vectors[np.where(labels == unique_label)[0]]\n                                                       .mean(axis=0))])\n\n            self.topic_vectors = unique_topics\n\n    def _calculate_topic_sizes(self, hierarchy=False):\n        if hierarchy:\n            topic_sizes = pd.Series(self.doc_top_reduced).value_counts()\n        else:\n            topic_sizes = pd.Series(self.doc_top).value_counts()\n\n        return topic_sizes\n\n    def _reorder_topics(self, hierarchy=False):\n\n        if hierarchy:\n            self.topic_vectors_reduced = self.topic_vectors_reduced[self.topic_sizes_reduced.index]\n            self.topic_words_reduced = self.topic_words_reduced[self.topic_sizes_reduced.index]\n            self.topic_word_scores_reduced = self.topic_word_scores_reduced[self.topic_sizes_reduced.index]\n            old2new = dict(zip(self.topic_sizes_reduced.index, range(self.topic_sizes_reduced.index.shape[0])))\n            self.doc_top_reduced = np.array([old2new[i] for i in self.doc_top_reduced])\n            self.hierarchy = [self.hierarchy[i] for i in self.topic_sizes_reduced.index]\n            self.topic_sizes_reduced.reset_index(drop=True, inplace=True)\n        else:\n            self.topic_vectors = self.topic_vectors[self.topic_sizes.index]\n            self.topic_words = self.topic_words[self.topic_sizes.index]\n            self.topic_word_scores = self.topic_word_scores[self.topic_sizes.index]\n            old2new = dict(zip(self.topic_sizes.index, range(self.topic_sizes.index.shape[0])))\n            self.doc_top = np.array([old2new[i] for i in self.doc_top])\n            self.topic_sizes.reset_index(drop=True, inplace=True)\n\n    @staticmethod\n    def _calculate_documents_topic(topic_vectors, document_vectors, dist=True, num_topics=None):\n        batch_size = 10000\n        doc_top = []\n        if dist:\n            doc_dist = []\n\n        if document_vectors.shape[0] > batch_size:\n            current = 0\n            batches = int(document_vectors.shape[0] / batch_size)\n            extra = document_vectors.shape[0] % batch_size\n\n            for ind in range(0, batches):\n                res = np.inner(document_vectors[current:current + batch_size], topic_vectors)\n\n                if num_topics is None:\n                    doc_top.extend(np.argmax(res, axis=1))\n                    if dist:\n                        doc_dist.extend(np.max(res, axis=1))\n                else:\n                    doc_top.extend(np.flip(np.argsort(res), axis=1)[:, :num_topics])\n                    if dist:\n                        doc_dist.extend(np.flip(np.sort(res), axis=1)[:, :num_topics])\n\n                current += batch_size\n\n            if extra > 0:\n                res = np.inner(document_vectors[current:current + extra], topic_vectors)\n\n                if num_topics is None:\n                    doc_top.extend(np.argmax(res, axis=1))\n                    if dist:\n                        doc_dist.extend(np.max(res, axis=1))\n                else:\n                    doc_top.extend(np.flip(np.argsort(res), axis=1)[:, :num_topics])\n                    if dist:\n                        doc_dist.extend(np.flip(np.sort(res), axis=1)[:, :num_topics])\n            if dist:\n                doc_dist = np.array(doc_dist)\n        else:\n            res = np.inner(document_vectors, topic_vectors)\n\n            if num_topics is None:\n                doc_top = np.argmax(res, axis=1)\n                if dist:\n                    doc_dist = np.max(res, axis=1)\n            else:\n                doc_top.extend(np.flip(np.argsort(res), axis=1)[:, :num_topics])\n                if dist:\n                    doc_dist.extend(np.flip(np.sort(res), axis=1)[:, :num_topics])\n\n        if num_topics is not None:\n            doc_top = np.array(doc_top)\n            if dist:\n                doc_dist = np.array(doc_dist)\n\n        if dist:\n            return doc_top, doc_dist\n        else:\n            return doc_top\n\n    def _find_topic_words_and_scores(self, topic_vectors):\n        topic_words = []\n        topic_word_scores = []\n\n        res = np.inner(topic_vectors, self.word_vectors)\n        top_words = np.flip(np.argsort(res, axis=1), axis=1)\n        top_scores = np.flip(np.sort(res, axis=1), axis=1)\n\n        for words, scores in zip(top_words, top_scores):\n            topic_words.append([self.vocab[i] for i in words[0:50]])\n            topic_word_scores.append(scores[0:50])\n\n        topic_words = np.array(topic_words)\n        topic_word_scores = np.array(topic_word_scores)\n\n        return topic_words, topic_word_scores\n\n    def _assign_documents_to_topic(self, document_vectors, hierarchy=False):\n\n        if hierarchy:\n            doc_top_new, doc_dist_new = self._calculate_documents_topic(self.topic_vectors_reduced,\n                                                                        document_vectors,\n                                                                        dist=True)\n\n            self.doc_top_reduced = np.array(list(self.doc_top_reduced) + list(doc_top_new))\n            self.doc_dist_reduced = np.array(list(self.doc_dist_reduced) + list(doc_dist_new))\n\n            topic_sizes_new = pd.Series(doc_top_new).value_counts()\n            for top in topic_sizes_new.index.tolist():\n                self.topic_sizes_reduced[top] += topic_sizes_new[top]\n            self.topic_sizes_reduced.sort_values(ascending=False, inplace=True)\n            self._reorder_topics(hierarchy)\n        else:\n            doc_top_new, doc_dist_new = self._calculate_documents_topic(self.topic_vectors, document_vectors, dist=True)\n            self.doc_top = np.array(list(self.doc_top) + list(doc_top_new))\n            self.doc_dist = np.array(list(self.doc_dist) + list(doc_dist_new))\n\n            topic_sizes_new = pd.Series(doc_top_new).value_counts()\n            for top in topic_sizes_new.index.tolist():\n                self.topic_sizes[top] += topic_sizes_new[top]\n            self.topic_sizes.sort_values(ascending=False, inplace=True)\n            self._reorder_topics(hierarchy)\n\n    def _unassign_documents_from_topic(self, doc_indexes, hierarchy=False):\n        if hierarchy:\n            doc_top_remove = self.doc_top_reduced[doc_indexes]\n            self.doc_top_reduced = np.delete(self.doc_top_reduced, doc_indexes, 0)\n            self.doc_dist_reduced = np.delete(self.doc_dist_reduced, doc_indexes, 0)\n            topic_sizes_remove = pd.Series(doc_top_remove).value_counts()\n            for top in topic_sizes_remove.index.tolist():\n                self.topic_sizes_reduced[top] -= topic_sizes_remove[top]\n            self.topic_sizes_reduced.sort_values(ascending=False, inplace=True)\n            self._reorder_topics(hierarchy)\n        else:\n            doc_top_remove = self.doc_top[doc_indexes]\n            self.doc_top = np.delete(self.doc_top, doc_indexes, 0)\n            self.doc_dist = np.delete(self.doc_dist, doc_indexes, 0)\n            topic_sizes_remove = pd.Series(doc_top_remove).value_counts()\n            for top in topic_sizes_remove.index.tolist():\n                self.topic_sizes[top] -= topic_sizes_remove[top]\n            self.topic_sizes.sort_values(ascending=False, inplace=True)\n            self._reorder_topics(hierarchy)\n\n    def _get_document_ids(self, doc_index):\n        return self.document_ids[doc_index]\n\n    def _get_document_indexes(self, doc_ids):\n        if self.document_ids is None:\n            return doc_ids\n        else:\n            return [self.doc_id2index[doc_id] for doc_id in doc_ids]\n\n    def _words2word_vectors(self, keywords):\n\n        return self.word_vectors[[self.word_indexes[word] for word in keywords]]\n\n    def _get_combined_vec(self, vecs, vecs_neg):\n\n        combined_vector = np.zeros(self.document_vectors.shape[1], dtype=np.float64)\n        for vec in vecs:\n            combined_vector += vec\n        for vec in vecs_neg:\n            combined_vector -= vec\n        combined_vector /= (len(vecs) + len(vecs_neg))\n        combined_vector = self._l2_normalize(combined_vector)\n\n        return combined_vector\n\n    @staticmethod\n    def _search_vectors_by_vector(vectors, vector, num_res):\n        ranks = np.inner(vectors, vector)\n        indexes = np.flip(np.argsort(ranks)[-num_res:])\n        scores = np.array([ranks[res] for res in indexes])\n\n        return indexes, scores\n\n    @staticmethod\n    def _check_hnswlib_status():\n        if not _HAVE_HNSWLIB:\n            raise ImportError(f\"Indexing is not available.\\n\\n\"\n                              \"Try: pip install top2vec[indexing]\\n\\n\"\n                              \"Alternatively try: pip install hnswlib\")\n\n    def _check_document_index_status(self):\n        if self.document_index is None:\n            raise ImportError(\"There is no document index.\\n\\n\"\n                              \"Call index_document_vectors method before setting use_index=True.\")\n\n    def _check_word_index_status(self):\n        if self.word_index is None:\n            raise ImportError(\"There is no word index.\\n\\n\"\n                              \"Call index_word_vectors method before setting use_index=True.\")\n\n    def _check_import_status(self):\n        if self.embedding_model in use_models:\n            if not _HAVE_TENSORFLOW:\n                raise ImportError(f\"{self.embedding_model} is not available.\\n\\n\"\n                                  \"Try: pip install top2vec[sentence_encoders]\\n\\n\"\n                                  \"Alternatively try: pip install tensorflow tensorflow_hub tensorflow_text\")\n        elif self.embedding_model in sbert_models:\n            if not _HAVE_TORCH:\n                raise ImportError(f\"{self.embedding_model} is not available.\\n\\n\"\n                                  \"Try: pip install top2vec[sentence_transformers]\\n\\n\"\n                                  \"Alternatively try: pip install torch sentence_transformers\")\n\n    def _check_model_status(self):\n        if self.embed is None:\n            if self.verbose is False:\n                logger.setLevel(logging.DEBUG)\n\n            if self.embedding_model in use_models:\n                if self.embedding_model_path is None:\n                    logger.info(f'Downloading {self.embedding_model} model')\n                    module = use_model_urls[self.embedding_model]\n\n                else:\n                    logger.info(f'Loading {self.embedding_model} model at {self.embedding_model_path}')\n                    module = self.embedding_model_path\n                self.embed = hub.load(module)\n\n            elif self.embedding_model in sbert_models:\n                if self.embedding_model_path is None:\n                    logger.info(f'Downloading {self.embedding_model} model')\n                    module = self.embedding_model\n                else:\n                    logger.info(f'Loading {self.embedding_model} model at {self.embedding_model_path}')\n                    module = self.embedding_model_path\n                model = SentenceTransformer(module)\n                self.embed = model.encode\n\n            elif callable(self.embedding_model):\n                self.embed = self.embedding_model\n                self.embedding_model = \"custom\"\n\n            elif self.embedding_model == \"custom\":\n                raise ValueError(\"Call set_embedding_model method and pass callable\"\n                                 \" embedding_model used during training.\")\n\n        if self.verbose is False:\n            logger.setLevel(logging.WARNING)\n\n    @staticmethod\n    def _less_than_zero(num, var_name):\n        if num < 0:\n            raise ValueError(f\"{var_name} cannot be less than 0.\")\n\n    def _validate_hierarchical_reduction(self):\n        if self.hierarchy is None:\n            raise ValueError(\"Hierarchical topic reduction has not been performed.\")\n\n    def _validate_hierarchical_reduction_num_topics(self, num_topics):\n        current_num_topics = len(self.topic_vectors)\n        if num_topics >= current_num_topics:\n            raise ValueError(f\"Number of topics must be less than {current_num_topics}.\")\n\n    def _validate_num_docs(self, num_docs):\n        self._less_than_zero(num_docs, \"num_docs\")\n        document_count = len(self.doc_top)\n        if num_docs > document_count:\n            raise ValueError(f\"num_docs cannot exceed the number of documents: {document_count}.\")\n\n    def _validate_num_topics(self, num_topics, reduced):\n        self._less_than_zero(num_topics, \"num_topics\")\n        if reduced:\n            topic_count = len(self.topic_vectors_reduced)\n            if num_topics > topic_count:\n                raise ValueError(f\"num_topics cannot exceed the number of reduced topics: {topic_count}.\")\n        else:\n            topic_count = len(self.topic_vectors)\n            if num_topics > topic_count:\n                raise ValueError(f\"num_topics cannot exceed the number of topics: {topic_count}.\")\n\n    def _validate_topic_num(self, topic_num, reduced):\n        self._less_than_zero(topic_num, \"topic_num\")\n\n        if reduced:\n            topic_count = len(self.topic_vectors_reduced) - 1\n            if topic_num > topic_count:\n                raise ValueError(f\"Invalid topic number: valid reduced topics numbers are 0 to {topic_count}.\")\n        else:\n            topic_count = len(self.topic_vectors) - 1\n            if topic_num > topic_count:\n                raise ValueError(f\"Invalid topic number: valid original topics numbers are 0 to {topic_count}.\")\n\n    def _validate_topic_search(self, topic_num, num_docs, reduced):\n        self._less_than_zero(num_docs, \"num_docs\")\n        if reduced:\n            if num_docs > self.topic_sizes_reduced[topic_num]:\n                raise ValueError(f\"Invalid number of documents: reduced topic {topic_num}\"\n                                 f\" only has {self.topic_sizes_reduced[topic_num]} documents.\")\n        else:\n            if num_docs > self.topic_sizes[topic_num]:\n                raise ValueError(f\"Invalid number of documents: original topic {topic_num}\"\n                                 f\" only has {self.topic_sizes[topic_num]} documents.\")\n\n    def _validate_doc_ids(self, doc_ids, doc_ids_neg):\n\n        if not (isinstance(doc_ids, list) or isinstance(doc_ids, np.ndarray)):\n            raise ValueError(\"doc_ids must be a list of string or int.\")\n        if not (isinstance(doc_ids_neg, list) or isinstance(doc_ids_neg, np.ndarray)):\n            raise ValueError(\"doc_ids_neg must be a list of string or int.\")\n\n        if isinstance(doc_ids, np.ndarray):\n            doc_ids = list(doc_ids)\n        if isinstance(doc_ids_neg, np.ndarray):\n            doc_ids_neg = list(doc_ids_neg)\n\n        doc_ids_all = doc_ids + doc_ids_neg\n\n        if self.document_ids is not None:\n            for doc_id in doc_ids_all:\n                if doc_id not in self.doc_id2index:\n                    raise ValueError(f\"{doc_id} is not a valid document id.\")\n        elif min(doc_ids) < 0:\n            raise ValueError(f\"{min(doc_ids)} is not a valid document id.\")\n        elif max(doc_ids) > len(self.doc_top) - 1:\n            raise ValueError(f\"{max(doc_ids)} is not a valid document id.\")\n\n    def _validate_keywords(self, keywords, keywords_neg):\n        if not (isinstance(keywords, list) or isinstance(keywords, np.ndarray)):\n            raise ValueError(\"keywords must be a list of strings.\")\n\n        if not (isinstance(keywords_neg, list) or isinstance(keywords_neg, np.ndarray)):\n            raise ValueError(\"keywords_neg must be a list of strings.\")\n\n        keywords_lower = [keyword.lower() for keyword in keywords]\n        keywords_neg_lower = [keyword.lower() for keyword in keywords_neg]\n\n        vocab = self.vocab\n        for word in keywords_lower + keywords_neg_lower:\n            if word not in vocab:\n                raise ValueError(f\"'{word}' has not been learned by the model so it cannot be searched.\")\n\n        return keywords_lower, keywords_neg_lower\n\n    def _validate_document_ids_add_doc(self, documents, document_ids):\n        if document_ids is None:\n            raise ValueError(\"Document ids need to be provided.\")\n        if len(documents) != len(document_ids):\n            raise ValueError(\"Document ids need to match number of documents.\")\n        if len(document_ids) != len(set(document_ids)):\n            raise ValueError(\"Document ids need to be unique.\")\n\n        if len(set(document_ids).intersection(self.document_ids)) > 0:\n            raise ValueError(\"Some document ids already exist in model.\")\n\n        if self.doc_id_type == np.str_:\n            if not all((isinstance(doc_id, str) or isinstance(doc_id, np.str_)) for doc_id in document_ids):\n                raise ValueError(\"Document ids need to be of type str.\")\n\n        if self.doc_id_type == np.int_:\n            if not all((isinstance(doc_id, int) or isinstance(doc_id, np.int_)) for doc_id in document_ids):\n                raise ValueError(\"Document ids need to be of type int.\")\n\n    @staticmethod\n    def _validate_documents(documents):\n        if not all((isinstance(doc, str) or isinstance(doc, np.str_)) for doc in documents):\n            raise ValueError(\"Documents need to be a list of strings.\")\n\n    @staticmethod\n    def _validate_query(query):\n        if not isinstance(query, str) or isinstance(query, np.str_):\n            raise ValueError(\"Query needs to be a string.\")\n\n    def _validate_vector(self, vector):\n        if not isinstance(vector, np.ndarray):\n            raise ValueError(\"Vector needs to be a numpy array.\")\n        vec_size = self.document_vectors.shape[1]\n        if not vector.shape[0] == vec_size:\n            raise ValueError(f\"Vector needs to be of {vec_size} dimensions.\")\n\n    def index_document_vectors(self, ef_construction=200, M=64):\n        \"\"\"\n        Creates an index of the document vectors using hnswlib. This will\n        lead to faster search times for models with a large number of\n        documents. \n        For more information on hnswlib see: https://github.com/nmslib/hnswlib\n        Parameters\n        ----------\n        ef_construction: int (Optional default 200)\n            This parameter controls the trade-off between index construction\n            time and index accuracy. Larger values will lead to greater\n            accuracy but will take longer to construct.\n        M: int (Optional default 64)\n            This parameter controls the trade-off between both index size as\n            well as construction time and accuracy. Larger values will lead to\n            greater accuracy but will result in a larger index as well as\n            longer construction time.\n            For more information on the parameters see:\n            https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md\n        \"\"\"\n\n        self._check_hnswlib_status()\n\n        document_vectors = self.document_vectors\n        vec_dim = document_vectors.shape[1]\n        num_vecs = document_vectors.shape[0]\n\n        index_ids = list(range(0, len(self.document_ids)))\n\n        self.index_id2doc_id = dict(zip(index_ids, self.document_ids))\n        self.doc_id2index_id = dict(zip(self.document_ids, index_ids))\n\n        self.document_index = hnswlib.Index(space='ip', dim=vec_dim)\n        self.document_index.init_index(max_elements=num_vecs, ef_construction=ef_construction, M=M)\n        self.document_index.add_items(document_vectors, index_ids)\n        self.documents_indexed = True\n\n    def index_word_vectors(self, ef_construction=200, M=64):\n        \"\"\"\n        Creates an index of the word vectors using hnswlib. This will\n        lead to faster search times for models with a large number of\n        words.\n        For more information on hnswlib see: https://github.com/nmslib/hnswlib\n        Parameters\n        ----------\n        ef_construction: int (Optional default 200)\n            This parameter controls the trade-off between index construction\n            time and index accuracy. Larger values will lead to greater\n            accuracy but will take longer to construct.\n        M: int (Optional default 64)\n            This parameter controls the trade-off between both index size as\n            well as construction time and accuracy. Larger values will lead to\n            greater accuracy but will result in a larger index as well as\n            longer construction time.\n            For more information on the parameters see:\n            https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md\n        \"\"\"\n        self._check_hnswlib_status()\n\n        word_vectors = self.word_vectors\n        vec_dim = word_vectors.shape[1]\n        num_vecs = word_vectors.shape[0]\n\n        index_ids = list(range(0, num_vecs))\n\n        self.word_index = hnswlib.Index(space='ip', dim=vec_dim)\n        self.word_index.init_index(max_elements=num_vecs, ef_construction=ef_construction, M=M)\n        self.word_index.add_items(word_vectors, index_ids)\n        self.words_indexed = True\n\n    def set_embedding_model(self, embedding_model):\n        \"\"\"\n        Set the embedding model. This is called after loading a saved Top2Vec\n        model which was trained with a passed callable embedding_model.\n        Parameters\n        ----------\n        embedding_model: callable\n            This must be the same embedding model used during training.\n        \"\"\"\n\n        if not callable(embedding_model):\n            raise ValueError(\"embedding_model must be callable.\")\n\n        self.embed = embedding_model\n\n    def update_embedding_model_path(self, embedding_model_path):\n        \"\"\"\n        Update the path of the embedding model to be loaded. The model will\n        no longer be downloaded but loaded from the path location.\n        Warning: the model at embedding_model_path must match the\n        embedding_model parameter type.\n        Parameters\n        ----------\n        embedding_model_path: Str\n            Path to downloaded embedding model.\n        \"\"\"\n        self.embedding_model_path = embedding_model_path\n\n    def change_to_download_embedding_model(self):\n        \"\"\"\n        Use automatic download to load embedding model used for training.\n        Top2Vec will no longer try and load the embedding model from a file\n        if a embedding_model path was previously added.\n        \"\"\"\n        self.embedding_model_path = None\n\n    def get_documents_topics(self, doc_ids, reduced=False, num_topics=1):\n        \"\"\"\n        Get document topics.\n        The topic of each document will be returned.\n        The corresponding original topics are returned unless reduced=True,\n        in which case the reduced topics will be returned.\n        Parameters\n        ----------\n        doc_ids: List of str, int\n            A unique value per document that is used for referring to\n            documents in search results. If ids were not given to the model,\n            the index of each document in the model is the id.\n        reduced: bool (Optional, default False)\n            Original topics are returned by default. If True the\n            reduced topics will be returned.\n        num_topics: int (Optional, default 1)\n            The number of topics to return per document.\n        Returns\n        -------\n        topic_nums: array of int, shape(len(doc_ids), num_topics)\n            The topic number(s) of the document corresponding to each doc_id.\n        topic_score: array of float, shape(len(doc_ids), num_topics)\n            Semantic similarity of document to topic(s). The cosine similarity\n            of the document and topic vector.\n        topics_words: array of shape(len(doc_ids), num_topics, 50)\n            For each topic the top 50 words are returned, in order\n            of semantic similarity to topic.\n            Example:\n            [['data', 'deep', 'learning' ... 'artificial'],          <Topic 4>\n            ['environment', 'warming', 'climate ... 'temperature']  <Topic 21>\n            ...]\n        word_scores: array of shape(num_topics, 50)\n            For each topic the cosine similarity scores of the\n            top 50 words to the topic are returned.\n            Example:\n            [[0.7132, 0.6473, 0.5700 ... 0.3455],  <Topic 4>\n            [0.7818', 0.7671, 0.7603 ... 0.6769]  <Topic 21>\n            ...]\n        \"\"\"\n        if reduced:\n            self._validate_hierarchical_reduction()\n\n        # make sure documents exist\n        self._validate_doc_ids(doc_ids, doc_ids_neg=[])\n\n        # get document indexes from ids\n        doc_indexes = self._get_document_indexes(doc_ids)\n\n        if num_topics == 1:\n            if reduced:\n                doc_topics = self.doc_top_reduced[doc_indexes]\n                doc_dist = self.doc_dist_reduced[doc_indexes]\n                topic_words = self.topic_words_reduced[doc_topics]\n                topic_word_scores = self.topic_word_scores_reduced[doc_topics]\n            else:\n                doc_topics = self.doc_top[doc_indexes]\n                doc_dist = self.doc_dist[doc_indexes]\n                topic_words = self.topic_words[doc_topics]\n                topic_word_scores = self.topic_word_scores[doc_topics]\n\n        else:\n            if reduced:\n                topic_vectors = self.topic_vectors_reduced\n            else:\n                topic_vectors = self.topic_vectors\n\n            doc_topics, doc_dist = self._calculate_documents_topic(topic_vectors,\n                                                                   self.document_vectors[doc_indexes],\n                                                                   num_topics=num_topics)\n\n            topic_words = np.array([self.topic_words[topics] for topics in doc_topics])\n            topic_word_scores = np.array([self.topic_word_scores[topics] for topics in doc_topics])\n\n        return doc_topics, doc_dist, topic_words, topic_word_scores\n\n    def add_documents(self,\n                      documents,\n                      doc_ids=None,\n                      tokenizer=None,\n                      use_embedding_model_tokenizer=False,\n                      embedding_batch_size=32):\n        \"\"\"\n        Update the model with new documents.\n        The documents will be added to the current model without changing\n        existing document, word and topic vectors. Topic sizes will be updated.\n        If adding a large quantity of documents relative to the current model\n        size, or documents containing a largely new vocabulary, a new model\n        should be trained for best results.\n        Parameters\n        ----------\n        documents: List of str\n        doc_ids: List of str, int (Optional)\n            Only required when doc_ids were given to the original model.\n            A unique value per document that will be used for referring to\n            documents in search results.\n        tokenizer: callable (Optional, default None)\n            Override the default tokenization method. If None then\n            gensim.utils.simple_preprocess will be used.\n        use_embedding_model_tokenizer: bool (Optional, default False)\n            If using an embedding model other than doc2vec, use the model's\n            tokenizer for document embedding.\n        embedding_batch_size: int (default=32)\n            Batch size for documents being embedded.\n        \"\"\"\n        # if tokenizer is not passed use default\n        if tokenizer is None:\n            tokenizer = default_tokenizer\n\n        # add documents\n        self._validate_documents(documents)\n        if self.documents is not None:\n            self.documents = np.array((list(self.documents) + list(documents)), dtype=\"object\")\n\n        # add document ids\n        if self.document_ids_provided is True:\n            self._validate_document_ids_add_doc(documents, doc_ids)\n            doc_ids_len = len(self.document_ids)\n            self.document_ids = np.array(list(self.document_ids) + list(doc_ids))\n            self.doc_id2index.update(dict(zip(doc_ids, list(range(doc_ids_len, doc_ids_len + len(doc_ids))))))\n\n        elif doc_ids is None:\n            num_docs = len(documents)\n            start_id = max(self.document_ids) + 1\n            doc_ids = list(range(start_id, start_id + num_docs))\n            doc_ids_len = len(self.document_ids)\n            self.document_ids = np.array(list(self.document_ids) + list(doc_ids))\n            self.doc_id2index.update(dict(zip(doc_ids, list(range(doc_ids_len, doc_ids_len + len(doc_ids))))))\n        else:\n            raise ValueError(\"doc_ids cannot be used because they were not provided to model during training.\")\n\n        if self.embedding_model == \"doc2vec\":\n            docs_processed = [tokenizer(doc) for doc in documents]\n            document_vectors = np.vstack([self.model.infer_vector(doc_words=doc,\n                                                                  alpha=0.025,\n                                                                  min_alpha=0.01,\n                                                                  epochs=100) for doc in docs_processed])\n\n            document_vectors = self._l2_normalize(document_vectors)\n            self.document_vectors = np.vstack([self.document_vectors, document_vectors])\n\n        else:\n            if use_embedding_model_tokenizer:\n                docs_training = documents\n            else:\n                docs_processed = [tokenizer(doc) for doc in documents]\n                docs_training = [' '.join(doc) for doc in docs_processed]\n            document_vectors = self._embed_documents(docs_training, embedding_batch_size)\n            self.document_vectors = np.vstack([self.document_vectors, document_vectors])\n\n        # update index\n        if self.documents_indexed:\n            # update capacity of index\n            current_max = self.document_index.get_max_elements()\n            updated_max = current_max + len(documents)\n            self.document_index.resize_index(updated_max)\n\n            # update index_id and doc_ids\n            start_index_id = max(self.index_id2doc_id.keys()) + 1\n            new_index_ids = list(range(start_index_id, start_index_id + len(doc_ids)))\n            self.index_id2doc_id.update(dict(zip(new_index_ids, doc_ids)))\n            self.doc_id2index_id.update(dict(zip(doc_ids, new_index_ids)))\n            self.document_index.add_items(document_vectors, new_index_ids)\n\n        # update topics\n        self._assign_documents_to_topic(document_vectors, hierarchy=False)\n\n        if self.hierarchy is not None:\n            self._assign_documents_to_topic(document_vectors, hierarchy=True)\n\n    def delete_documents(self, doc_ids):\n        \"\"\"\n        Delete documents from current model.\n        Warning: If document ids were not used in original model, deleting\n        documents will change the indexes and therefore doc_ids.\n        The documents will be deleted from the current model without changing\n        existing document, word and topic vectors. Topic sizes will be updated.\n        If deleting a large quantity of documents relative to the current model\n        size a new model should be trained for best results.\n        Parameters\n        ----------\n        doc_ids: List of str, int\n            A unique value per document that is used for referring to documents\n            in search results.\n        \"\"\"\n        # make sure documents exist\n        self._validate_doc_ids(doc_ids, doc_ids_neg=[])\n\n        # update index\n        if self.documents_indexed:\n            # delete doc_ids from index\n            index_ids = [self.doc_id2index_id(doc_id) for doc_id in doc_ids]\n            for index_id in index_ids:\n                self.document_index.mark_deleted(index_id)\n            # update index_id and doc_ids\n            for doc_id in doc_ids:\n                self.doc_id2index_id.pop(doc_id)\n            for index_id in index_ids:\n                self.index_id2doc_id.pop(index_id)\n\n        # get document indexes from ids\n        doc_indexes = self._get_document_indexes(doc_ids)\n\n        # delete documents\n        if self.documents is not None:\n            self.documents = np.delete(self.documents, doc_indexes, 0)\n\n        # delete document ids\n        if self.document_ids is not None:\n            for doc_id in doc_ids:\n                self.doc_id2index.pop(doc_id)\n            keys = list(self.doc_id2index.keys())\n            self.document_ids = np.array(keys)\n            values = list(range(0, len(self.doc_id2index.values())))\n            self.doc_id2index = dict(zip(keys, values))\n\n        # delete document vectors\n        self.document_vectors = np.delete(self.document_vectors, doc_indexes, 0)\n\n        # update topics\n        self._unassign_documents_from_topic(doc_indexes, hierarchy=False)\n\n        if self.hierarchy is not None:\n            self._unassign_documents_from_topic(doc_indexes, hierarchy=True)\n\n    def get_num_topics(self, reduced=False):\n        \"\"\"\n        Get number of topics.\n        This is the number of topics Top2Vec has found in the data by default.\n        If reduced is True, the number of reduced topics is returned.\n        Parameters\n        ----------\n        reduced: bool (Optional, default False)\n            The number of original topics will be returned by default. If True\n            will return the number of reduced topics, if hierarchical topic\n            reduction has been performed.\n        Returns\n        -------\n        num_topics: int\n        \"\"\"\n\n        if reduced:\n            self._validate_hierarchical_reduction()\n            return len(self.topic_vectors_reduced)\n        else:\n            return len(self.topic_vectors)\n\n    def get_topic_sizes(self, reduced=False):\n        \"\"\"\n        Get topic sizes.\n        The number of documents most similar to each topic. Topics are\n        in increasing order of size.\n        The sizes of the original topics is returned unless reduced=True,\n        in which case the sizes of the reduced topics will be returned.\n        Parameters\n        ----------\n        reduced: bool (Optional, default False)\n            Original topic sizes are returned by default. If True the\n            reduced topic sizes will be returned.\n        Returns\n        -------\n        topic_sizes: array of int, shape(num_topics)\n            The number of documents most similar to the topic.\n        topic_nums: array of int, shape(num_topics)\n            The unique number of every topic will be returned.\n        \"\"\"\n        if reduced:\n            self._validate_hierarchical_reduction()\n            return np.array(self.topic_sizes_reduced.values), np.array(self.topic_sizes_reduced.index)\n        else:\n            return np.array(self.topic_sizes.values), np.array(self.topic_sizes.index)\n\n    def get_topics(self, num_topics=None, reduced=False):\n        \"\"\"\n        Get topics, ordered by decreasing size. All topics are returned\n        if num_topics is not specified.\n        The original topics found are returned unless reduced=True,\n        in which case reduced topics will be returned.\n        Each topic will consist of the top 50 semantically similar words\n        to the topic. These are the 50 words closest to topic vector\n        along with cosine similarity of each word from vector. The\n        higher the score the more relevant the word is to the topic.\n        Parameters\n        ----------\n        num_topics: int, (Optional)\n            Number of topics to return.\n        reduced: bool (Optional, default False)\n            Original topics are returned by default. If True the\n            reduced topics will be returned.\n        Returns\n        -------\n        topics_words: array of shape(num_topics, 50)\n            For each topic the top 50 words are returned, in order\n            of semantic similarity to topic.\n            \n            Example:\n            [['data', 'deep', 'learning' ... 'artificial'],         <Topic 0>\n            ['environment', 'warming', 'climate ... 'temperature']  <Topic 1>\n            ...]\n        word_scores: array of shape(num_topics, 50)\n            For each topic the cosine similarity scores of the\n            top 50 words to the topic are returned.\n            \n            Example:\n            [[0.7132, 0.6473, 0.5700 ... 0.3455],  <Topic 0>\n            [0.7818', 0.7671, 0.7603 ... 0.6769]   <Topic 1>\n            ...]\n        topic_nums: array of int, shape(num_topics)\n            The unique number of every topic will be returned.\n        \"\"\"\n        if reduced:\n            self._validate_hierarchical_reduction()\n\n            if num_topics is None:\n                num_topics = len(self.topic_vectors_reduced)\n            else:\n                self._validate_num_topics(num_topics, reduced)\n\n            return self.topic_words_reduced[0:num_topics], self.topic_word_scores_reduced[0:num_topics], np.array(\n                range(0, num_topics))\n        else:\n\n            if num_topics is None:\n                num_topics = len(self.topic_vectors)\n            else:\n                self._validate_num_topics(num_topics, reduced)\n\n            return self.topic_words[0:num_topics], self.topic_word_scores[0:num_topics], np.array(range(0, num_topics))\n\n    def get_topic_hierarchy(self):\n        \"\"\"\n        Get the hierarchy of reduced topics. The mapping of each original topic\n        to the reduced topics is returned.\n        Hierarchical topic reduction must be performed before calling this\n        method.\n        Returns\n        -------\n        hierarchy: list of ints\n            Each index of the hierarchy corresponds to the topic number of a\n            reduced topic. For each reduced topic the topic numbers of the\n            original topics that were merged to create it are listed.\n            Example:\n            [[3]  <Reduced Topic 0> contains original Topic 3\n            [2,4] <Reduced Topic 1> contains original Topics 2 and 4\n            [0,1] <Reduced Topic 3> contains original Topics 0 and 1\n            ...]\n        \"\"\"\n\n        self._validate_hierarchical_reduction()\n\n        return self.hierarchy\n\n    def hierarchical_topic_reduction(self, num_topics):\n        \"\"\"\n        Reduce the number of topics discovered by Top2Vec.\n        The most representative topics of the corpus will be found, by\n        iteratively merging each smallest topic to the most similar topic until\n        num_topics is reached.\n        Parameters\n        ----------\n        num_topics: int\n            The number of topics to reduce to.\n        Returns\n        -------\n        hierarchy: list of ints\n            Each index of hierarchy corresponds to the reduced topics, for each\n            reduced topic the indexes of the original topics that were merged\n            to create it are listed.\n            Example:\n            [[3]  <Reduced Topic 0> contains original Topic 3\n            [2,4] <Reduced Topic 1> contains original Topics 2 and 4\n            [0,1] <Reduced Topic 3> contains original Topics 0 and 1\n            ...]\n        \"\"\"\n        self._validate_hierarchical_reduction_num_topics(num_topics)\n\n        num_topics_current = self.topic_vectors.shape[0]\n        top_vecs = self.topic_vectors\n        top_sizes = [self.topic_sizes[i] for i in range(0, len(self.topic_sizes))]\n        hierarchy = [[i] for i in range(self.topic_vectors.shape[0])]\n\n        count = 0\n        interval = max(int(self.document_vectors.shape[0] / 50000), 1)\n\n        while num_topics_current > num_topics:\n\n            # find smallest and most similar topics\n            smallest = np.argmin(top_sizes)\n            res = np.inner(top_vecs[smallest], top_vecs)\n            sims = np.flip(np.argsort(res))\n            most_sim = sims[1]\n            if most_sim == smallest:\n                most_sim = sims[0]\n\n            # calculate combined topic vector\n            top_vec_smallest = top_vecs[smallest]\n            smallest_size = top_sizes[smallest]\n\n            top_vec_most_sim = top_vecs[most_sim]\n            most_sim_size = top_sizes[most_sim]\n\n            combined_vec = self._l2_normalize(((top_vec_smallest * smallest_size) +\n                                               (top_vec_most_sim * most_sim_size)) / (smallest_size + most_sim_size))\n\n            # update topic vectors\n            ix_keep = list(range(len(top_vecs)))\n            ix_keep.remove(smallest)\n            ix_keep.remove(most_sim)\n            top_vecs = top_vecs[ix_keep]\n            top_vecs = np.vstack([top_vecs, combined_vec])\n            num_topics_current = top_vecs.shape[0]\n\n            # update topics sizes\n            if count % interval == 0:\n                doc_top = self._calculate_documents_topic(topic_vectors=top_vecs,\n                                                          document_vectors=self.document_vectors,\n                                                          dist=False)\n                topic_sizes = pd.Series(doc_top).value_counts()\n                top_sizes = [topic_sizes[i] for i in range(0, len(topic_sizes))]\n\n            else:\n                smallest_size = top_sizes.pop(smallest)\n                if most_sim < smallest:\n                    most_sim_size = top_sizes.pop(most_sim)\n                else:\n                    most_sim_size = top_sizes.pop(most_sim - 1)\n                combined_size = smallest_size + most_sim_size\n                top_sizes.append(combined_size)\n\n            count += 1\n\n            # update topic hierarchy\n            smallest_inds = hierarchy.pop(smallest)\n            if most_sim < smallest:\n                most_sim_inds = hierarchy.pop(most_sim)\n            else:\n                most_sim_inds = hierarchy.pop(most_sim - 1)\n\n            combined_inds = smallest_inds + most_sim_inds\n            hierarchy.append(combined_inds)\n\n        # re-calculate topic vectors from clusters\n        doc_top = self._calculate_documents_topic(topic_vectors=top_vecs,\n                                                  document_vectors=self.document_vectors,\n                                                  dist=False)\n        self.topic_vectors_reduced = self._l2_normalize(np.vstack([self.document_vectors\n                                                                   [np.where(doc_top == label)[0]]\n                                                                  .mean(axis=0) for label in set(doc_top)]))\n\n        self.hierarchy = hierarchy\n\n        # assign documents to topic\n        self.doc_top_reduced, self.doc_dist_reduced = self._calculate_documents_topic(self.topic_vectors_reduced,\n                                                                                      self.document_vectors)\n        # find topic words and scores\n        self.topic_words_reduced, self.topic_word_scores_reduced = self._find_topic_words_and_scores(\n            topic_vectors=self.topic_vectors_reduced)\n\n        # calculate topic sizes\n        self.topic_sizes_reduced = self._calculate_topic_sizes(hierarchy=True)\n\n        # re-order topics\n        self._reorder_topics(hierarchy=True)\n\n        return self.hierarchy\n\n    def query_documents(self, query, num_docs, return_documents=True, use_index=False, ef=None, tokenizer=None):\n        \"\"\"\n        Semantic search of documents using a text query.\n        The most semantically similar documents to the query will be returned.\n        Parameters\n        ----------\n        query: string\n            Any sequence of text. This could be an actual question, a sentence,\n            a paragraph or a document.\n        num_docs: int\n            Number of documents to return.\n        return_documents: bool (Optional default True)\n            Determines if the documents will be returned. If they were not\n            saved in the model they will not be returned.\n        use_index: bool (Optional default False)\n            If index_documents method has been called, setting this to True\n            will speed up search for models with large number of documents.\n        ef: int (Optional default None)\n            Higher ef leads to more accurate but slower search. This value\n            must be higher than num_docs.\n            For more information see:\n            https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md\n        tokenizer: callable (Optional, default None)\n            ** For doc2vec embedding model only **\n            Override the default tokenization method. If None then\n            gensim.utils.simple_preprocess will be used.\n        Returns\n        -------\n        documents: (Optional) array of str, shape(num_docs)\n            The documents in a list, the most similar are first.\n            Will only be returned if the documents were saved and if\n            return_documents is set to True.\n        doc_scores: array of float, shape(num_docs)\n            Semantic similarity of document to vector. The cosine similarity of\n            the document and vector.\n        doc_ids: array of int, shape(num_docs)\n            Unique ids of documents. If ids were not given to the model, the\n            index of the document in the model will be returned.\n        \"\"\"\n\n        self._validate_query(query)\n        self._validate_num_docs(num_docs)\n\n        if self.embedding_model != \"doc2vec\":\n            query_vec = self._embed_query(query)\n\n        else:\n\n            # if tokenizer is not passed use default\n            if tokenizer is None:\n                tokenizer = default_tokenizer\n\n            tokenized_query = tokenizer(query)\n\n            query_vec = self.model.infer_vector(doc_words=tokenized_query,\n                                                alpha=0.025,\n                                                min_alpha=0.01,\n                                                epochs=100)\n\n        return self.search_documents_by_vector(query_vec, num_docs, return_documents=return_documents,\n                                               use_index=use_index, ef=ef)\n\n    def query_topics(self, query, num_topics, reduced=False, tokenizer=None):\n        \"\"\"\n        Semantic search of topics using text query.\n        These are the topics closest to the vector. Topics are ordered by\n        proximity to the vector. Successive topics in the list are less\n        semantically similar to the vector.\n        Parameters\n        ----------\n        query: string\n            Any sequence of text. This could be an actual question, a sentence,\n            a paragraph or a document.\n        num_topics: int\n            Number of documents to return.\n        reduced: bool (Optional, default False)\n            Original topics are searched by default. If True the\n            reduced topics will be searched.\n        tokenizer: callable (Optional, default None)\n            ** For doc2vec embedding model only **\n            Override the default tokenization method. If None then\n            gensim.utils.simple_preprocess will be used.\n        Returns\n        -------\n        topics_words: array of shape (num_topics, 50)\n            For each topic the top 50 words are returned, in order of semantic\n            similarity to topic.\n            Example:\n            [['data', 'deep', 'learning' ... 'artificial'],           <Topic 0>\n            ['environment', 'warming', 'climate ... 'temperature']    <Topic 1>\n            ...]\n        word_scores: array of shape (num_topics, 50)\n            For each topic the cosine similarity scores of the top 50 words\n            to the topic are returned.\n            Example:\n            [[0.7132, 0.6473, 0.5700 ... 0.3455],     <Topic 0>\n            [0.7818', 0.7671, 0.7603 ... 0.6769]     <Topic 1>\n            ...]\n        topic_scores: array of float, shape(num_topics)\n            For each topic the cosine similarity to the search keywords will be\n            returned.\n        topic_nums: array of int, shape(num_topics)\n            The unique number of every topic will be returned.\n        \"\"\"\n\n        self._validate_query(query)\n\n        if self.embedding_model != \"doc2vec\":\n            query_vec = self._embed_query(query)\n\n        else:\n\n            # if tokenizer is not passed use default\n            if tokenizer is None:\n                tokenizer = default_tokenizer\n\n            tokenized_query = tokenizer(query)\n\n            query_vec = self.model.infer_vector(doc_words=tokenized_query,\n                                                alpha=0.025,\n                                                min_alpha=0.01,\n                                                epochs=100)\n\n        return self.search_topics_by_vector(query_vec, num_topics=num_topics, reduced=reduced)\n\n    def search_documents_by_vector(self, vector, num_docs, return_documents=True, use_index=False, ef=None):\n        \"\"\"\n        Semantic search of documents using a vector.\n        These are the documents closest to the vector. Documents are\n        ordered by proximity to the vector. Successive documents in the\n        list are less semantically similar to the vector.\n        Parameters\n        ----------\n        vector: array of shape(vector dimension, 1)\n            The vector dimension should be the same as the vectors in\n            the topic_vectors variable. (i.e. model.topic_vectors.shape[1])\n        num_docs: int\n            Number of documents to return.\n        return_documents: bool (Optional default True)\n            Determines if the documents will be returned. If they were not\n            saved in the model they will not be returned.\n        use_index: bool (Optional default False)\n            If index_documents method has been called, setting this to True\n            will speed up search for models with large number of documents.\n        ef: int (Optional default None)\n            Higher ef leads to more accurate but slower search. This value\n            must be higher than num_docs.\n            For more information see:\n            https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md\n        Returns\n        -------\n        documents: (Optional) array of str, shape(num_docs)\n            The documents in a list, the most similar are first.\n            Will only be returned if the documents were saved and if\n            return_documents is set to True.\n        doc_scores: array of float, shape(num_docs)\n            Semantic similarity of document to vector. The cosine similarity of\n            the document and vector.\n        doc_ids: array of int, shape(num_docs)\n            Unique ids of documents. If ids were not given to the model, the\n            index of the document in the model will be returned.\n        \"\"\"\n        self._validate_vector(vector)\n        self._validate_num_docs(num_docs)\n\n        vector = self._l2_normalize(vector)\n\n        if use_index:\n            self._check_document_index_status()\n\n            if ef is not None:\n                self.document_index.set_ef(ef)\n            else:\n                self.document_index.set_ef(num_docs)\n\n            index_ids, doc_scores = self.document_index.knn_query(vector, k=num_docs)\n            index_ids = index_ids[0]\n            doc_ids = np.array([self.index_id2doc_id[index_id] for index_id in index_ids])\n            doc_scores = doc_scores[0]\n            doc_scores = np.array([1 - score for score in doc_scores])\n            doc_indexes = self._get_document_indexes(doc_ids)\n        else:\n            doc_indexes, doc_scores = self._search_vectors_by_vector(self.document_vectors,\n                                                                     vector, num_docs)\n            doc_ids = self._get_document_ids(doc_indexes)\n\n        if self.documents is not None and return_documents:\n            documents = self.documents[doc_indexes]\n            return documents, doc_scores, doc_ids\n        else:\n            return doc_scores, doc_ids\n\n    def search_words_by_vector(self, vector, num_words, use_index=False, ef=None):\n        \"\"\"\n        Semantic search of words using a vector.\n        These are the words closest to the vector. Words are ordered by\n        proximity to the vector. Successive words in the list are less\n        semantically similar to the vector.\n        Parameters\n        ----------\n        vector: array of shape(vector dimension, 1)\n            The vector dimension should be the same as the vectors in\n            the topic_vectors variable. (i.e. model.topic_vectors.shape[1])\n        num_words: int\n            Number of words to return.\n        use_index: bool (Optional default False)\n            If index_words method has been called, setting this to True will\n            speed up search for models with large number of words.\n        ef: int (Optional default None)\n            Higher ef leads to more accurate but slower search. This value\n            must be higher than num_docs.\n            For more information see:\n            https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md\n        Returns\n        -------\n        words: array of str, shape(num_words)\n            The words in a list, the most similar are first.\n        word_scores: array of float, shape(num_words)\n            Semantic similarity of word to vector. The cosine similarity of\n            the word and vector.\n        \"\"\"\n\n        self._validate_vector(vector)\n\n        vector = self._l2_normalize(vector)\n\n        if use_index:\n            self._check_word_index_status()\n\n            if ef is not None:\n                self.word_index.set_ef(ef)\n            else:\n                self.word_index.set_ef(num_words)\n\n            word_indexes, word_scores = self.word_index.knn_query(vector, k=num_words)\n            word_indexes = word_indexes[0]\n            word_scores = word_scores[0]\n            word_scores = np.array([1 - score for score in word_scores])\n\n        else:\n            word_indexes, word_scores = self._search_vectors_by_vector(self.word_vectors,\n                                                                       vector, num_words)\n\n        words = np.array([self.vocab[index] for index in word_indexes])\n\n        return words, word_scores\n\n    def search_topics_by_vector(self, vector, num_topics, reduced=False):\n        \"\"\"\n        Semantic search of topics using keywords.\n        These are the topics closest to the vector. Topics are ordered by\n        proximity to the vector. Successive topics in the list are less\n        semantically similar to the vector.\n        Parameters\n        ----------\n        vector: array of shape(vector dimension, 1)\n            The vector dimension should be the same as the vectors in\n            the topic_vectors variable. (i.e. model.topic_vectors.shape[1])\n        num_topics: int\n            Number of documents to return.\n        reduced: bool (Optional, default False)\n            Original topics are searched by default. If True the\n            reduced topics will be searched.\n        Returns\n        -------\n        topics_words: array of shape (num_topics, 50)\n            For each topic the top 50 words are returned, in order of semantic\n            similarity to topic.\n            Example:\n            [['data', 'deep', 'learning' ... 'artificial'],           <Topic 0>\n            ['environment', 'warming', 'climate ... 'temperature']    <Topic 1>\n            ...]\n        word_scores: array of shape (num_topics, 50)\n            For each topic the cosine similarity scores of the top 50 words\n            to the topic are returned.\n            Example:\n            [[0.7132, 0.6473, 0.5700 ... 0.3455],     <Topic 0>\n            [0.7818', 0.7671, 0.7603 ... 0.6769]     <Topic 1>\n            ...]\n        topic_scores: array of float, shape(num_topics)\n            For each topic the cosine similarity to the search keywords will be\n            returned.\n        topic_nums: array of int, shape(num_topics)\n            The unique number of every topic will be returned.\n        \"\"\"\n\n        self._validate_vector(vector)\n        self._validate_num_topics(num_topics, reduced)\n\n        vector = self._l2_normalize(vector)\n\n        if reduced:\n            self._validate_hierarchical_reduction()\n\n            topic_nums, topic_scores = self._search_vectors_by_vector(self.topic_vectors_reduced,\n                                                                      vector, num_topics)\n            topic_words = [self.topic_words_reduced[topic] for topic in topic_nums]\n            word_scores = [self.topic_word_scores_reduced[topic] for topic in topic_nums]\n\n        else:\n            topic_nums, topic_scores = self._search_vectors_by_vector(self.topic_vectors,\n                                                                      vector, num_topics)\n            topic_words = [self.topic_words[topic] for topic in topic_nums]\n            word_scores = [self.topic_word_scores[topic] for topic in topic_nums]\n\n        return topic_words, word_scores, topic_scores, topic_nums\n\n    def search_documents_by_topic(self, topic_num, num_docs, return_documents=True, reduced=False):\n        \"\"\"\n        Get the most semantically similar documents to the topic.\n        These are the documents closest to the topic vector. Documents are\n        ordered by proximity to the topic vector. Successive documents in the\n        list are less semantically similar to the topic.\n        Parameters\n        ----------\n        topic_num: int\n            The topic number to search.\n        num_docs: int\n            Number of documents to return.\n        return_documents: bool (Optional default True)\n            Determines if the documents will be returned. If they were not\n            saved in the model they will not be returned.\n        reduced: bool (Optional, default False)\n            Original topics are used to search by default. If True the\n            reduced topics will be used.\n        Returns\n        -------\n        documents: (Optional) array of str, shape(num_docs)\n            The documents in a list, the most similar are first.\n            Will only be returned if the documents were saved and if\n            return_documents is set to True.\n        doc_scores: array of float, shape(num_docs)\n            Semantic similarity of document to topic. The cosine similarity of\n            the document and topic vector.\n        doc_ids: array of int, shape(num_docs)\n            Unique ids of documents. If ids were not given to the model, the\n            index of the document in the model will be returned.\n        \"\"\"\n\n        if reduced:\n            self._validate_hierarchical_reduction()\n            self._validate_topic_num(topic_num, reduced)\n            self._validate_topic_search(topic_num, num_docs, reduced)\n\n            topic_document_indexes = np.where(self.doc_top_reduced == topic_num)[0]\n            topic_document_indexes_ordered = np.flip(np.argsort(self.doc_dist_reduced[topic_document_indexes]))\n            doc_indexes = topic_document_indexes[topic_document_indexes_ordered][0:num_docs]\n            doc_scores = self.doc_dist_reduced[doc_indexes]\n            doc_ids = self._get_document_ids(doc_indexes)\n\n        else:\n\n            self._validate_topic_num(topic_num, reduced)\n            self._validate_topic_search(topic_num, num_docs, reduced)\n\n            topic_document_indexes = np.where(self.doc_top == topic_num)[0]\n            topic_document_indexes_ordered = np.flip(np.argsort(self.doc_dist[topic_document_indexes]))\n            doc_indexes = topic_document_indexes[topic_document_indexes_ordered][0:num_docs]\n            doc_scores = self.doc_dist[doc_indexes]\n            doc_ids = self._get_document_ids(doc_indexes)\n\n        if self.documents is not None and return_documents:\n            documents = self.documents[doc_indexes]\n            return documents, doc_scores, doc_ids\n        else:\n            return doc_scores, doc_ids\n\n    def search_documents_by_keywords(self, keywords, num_docs, keywords_neg=None, return_documents=True,\n                                     use_index=False, ef=None):\n        \"\"\"\n        Semantic search of documents using keywords.\n        The most semantically similar documents to the combination of the\n        keywords will be returned. If negative keywords are provided, the\n        documents will be semantically dissimilar to those words. Too many\n        keywords or certain combinations of words may give strange results.\n        This method finds an average vector(negative keywords are subtracted)\n        of all the keyword vectors and returns the documents closest to the\n        resulting vector.\n        Parameters\n        ----------\n        keywords: List of str\n            List of positive keywords being used for search of semantically\n            similar documents.\n        keywords_neg: List of str (Optional)\n            List of negative keywords being used for search of semantically\n            dissimilar documents.\n        num_docs: int\n            Number of documents to return.\n        return_documents: bool (Optional default True)\n            Determines if the documents will be returned. If they were not\n            saved in the model they will also not be returned.\n        use_index: bool (Optional default False)\n            If index_documents method has been called, setting this to True\n            will speed up search for models with large number of documents.\n        ef: int (Optional default None)\n            Higher ef leads to more accurate but slower search. This value\n            must be higher than num_docs.\n            For more information see:\n            https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md\n        Returns\n        -------\n        documents: (Optional) array of str, shape(num_docs)\n            The documents in a list, the most similar are first.\n            Will only be returned if the documents were saved and if\n            return_documents is set to True.\n        doc_scores: array of float, shape(num_docs)\n            Semantic similarity of document to keywords. The cosine similarity\n            of the document and average of keyword vectors.\n        doc_ids: array of int, shape(num_docs)\n            Unique ids of documents. If ids were not given to the model, the\n            index of the document in the model will be returned.\n        \"\"\"\n\n        if keywords_neg is None:\n            keywords_neg = []\n\n        self._validate_num_docs(num_docs)\n        keywords, keywords_neg = self._validate_keywords(keywords, keywords_neg)\n        word_vecs = self._words2word_vectors(keywords)\n        neg_word_vecs = self._words2word_vectors(keywords_neg)\n\n        if use_index:\n            self._check_document_index_status()\n            combined_vector = self._get_combined_vec(word_vecs, neg_word_vecs)\n            return self.search_documents_by_vector(combined_vector, num_docs, return_documents=return_documents,\n                                                   use_index=True, ef=ef)\n\n        if self.embedding_model == 'doc2vec':\n            sim_docs = self.model.docvecs.most_similar(positive=word_vecs,\n                                                       negative=neg_word_vecs,\n                                                       topn=num_docs)\n            doc_indexes = [doc[0] for doc in sim_docs]\n            doc_scores = np.array([doc[1] for doc in sim_docs])\n        else:\n            combined_vector = self._get_combined_vec(word_vecs, neg_word_vecs)\n            doc_indexes, doc_scores = self._search_vectors_by_vector(self.document_vectors,\n                                                                     combined_vector, num_docs)\n\n        doc_ids = self._get_document_ids(doc_indexes)\n\n        if self.documents is not None and return_documents:\n            documents = self.documents[doc_indexes]\n            return documents, doc_scores, doc_ids\n        else:\n            return doc_scores, doc_ids\n\n    def similar_words(self, keywords, num_words, keywords_neg=None, use_index=False, ef=None):\n        \"\"\"\n        Semantic similarity search of words.\n        The most semantically similar word to the combination of the keywords\n        will be returned. If negative keywords are provided, the words will be\n        semantically dissimilar to those words. Too many keywords or certain\n        combinations of words may give strange results. This method finds an\n        average vector(negative keywords are subtracted) of all the keyword\n        vectors and returns the words closest to the resulting vector.\n        Parameters\n        ----------\n        keywords: List of str\n            List of positive keywords being used for search of semantically\n            similar words.\n        keywords_neg: List of str\n            List of negative keywords being used for search of semantically\n            dissimilar words.\n        num_words: int\n            Number of words to return.\n        use_index: bool (Optional default False)\n            If index_words method has been called, setting this to True will\n            speed up search for models with large number of words.\n        ef: int (Optional default None)\n            Higher ef leads to more accurate but slower search. This value\n            must be higher than num_docs.\n            For more information see:\n            https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md\n        Returns\n        -------\n        words: array of str, shape(num_words)\n            The words in a list, the most similar are first.\n        word_scores: array of float, shape(num_words)\n            Semantic similarity of word to keywords. The cosine similarity of\n            the word and average of keyword vectors.\n        \"\"\"\n        if keywords_neg is None:\n            keywords_neg = []\n\n        keywords, keywords_neg = self._validate_keywords(keywords, keywords_neg)\n\n        word_vecs = self._words2word_vectors(keywords)\n        neg_word_vecs = self._words2word_vectors(keywords_neg)\n        combined_vector = self._get_combined_vec(word_vecs, neg_word_vecs)\n\n        num_res = min(num_words + len(keywords) + len(keywords_neg), self.word_vectors.shape[0])\n\n        # if use_index:\n        words, word_scores = self.search_words_by_vector(vector=combined_vector,\n                                                         num_words=num_res,\n                                                         use_index=use_index,\n                                                         ef=ef)\n\n        res_indexes = [index for index, word in enumerate(words)\n                       if word not in list(keywords) + list(keywords_neg)][:num_words]\n        words = words[res_indexes]\n        word_scores = word_scores[res_indexes]\n\n        return words, word_scores\n\n    def search_topics(self, keywords, num_topics, keywords_neg=None, reduced=False):\n        \"\"\"\n        Semantic search of topics using keywords.\n        The most semantically similar topics to the combination of the keywords\n        will be returned. If negative keywords are provided, the topics will be\n        semantically dissimilar to those words. Topics will be ordered by\n        decreasing similarity to the keywords. Too many keywords or certain\n        combinations of words may give strange results. This method finds an\n        average vector(negative keywords are subtracted) of all the keyword\n        vectors and returns the topics closest to the resulting vector.\n        Parameters\n        ----------\n        keywords: List of str\n            List of positive keywords being used for search of semantically\n            similar documents.\n        keywords_neg: (Optional) List of str\n            List of negative keywords being used for search of semantically\n            dissimilar documents.\n        num_topics: int\n            Number of documents to return.\n        reduced: bool (Optional, default False)\n            Original topics are searched by default. If True the\n            reduced topics will be searched.\n        Returns\n        -------\n        topics_words: array of shape (num_topics, 50)\n            For each topic the top 50 words are returned, in order of semantic\n            similarity to topic.\n            \n            Example:\n            [['data', 'deep', 'learning' ... 'artificial'],           <Topic 0>\n            ['environment', 'warming', 'climate ... 'temperature']    <Topic 1>\n            ...]\n        word_scores: array of shape (num_topics, 50)\n            For each topic the cosine similarity scores of the top 50 words\n            to the topic are returned.\n            \n            Example:\n            [[0.7132, 0.6473, 0.5700 ... 0.3455],     <Topic 0>\n            [0.7818', 0.7671, 0.7603 ... 0.6769]     <Topic 1>\n            ...]\n        topic_scores: array of float, shape(num_topics)\n            For each topic the cosine similarity to the search keywords will be\n            returned.\n        topic_nums: array of int, shape(num_topics)\n            The unique number of every topic will be returned.\n        \"\"\"\n        if keywords_neg is None:\n            keywords_neg = []\n\n        keywords, keywords_neg = self._validate_keywords(keywords, keywords_neg)\n        word_vecs = self._words2word_vectors(keywords)\n        neg_word_vecs = self._words2word_vectors(keywords_neg)\n        combined_vector = self._get_combined_vec(word_vecs, neg_word_vecs)\n\n        return self.search_topics_by_vector(combined_vector, num_topics=num_topics, reduced=reduced)\n\n    def search_documents_by_documents(self, doc_ids, num_docs, doc_ids_neg=None, return_documents=True,\n                                      use_index=False, ef=None):\n        \"\"\"\n        Semantic similarity search of documents.\n        The most semantically similar documents to the semantic combination of\n        document ids provided will be returned. If negative document ids are\n        provided, the documents will be semantically dissimilar to those\n        document ids. Documents will be ordered by decreasing similarity. This\n        method finds the closest document vectors to the provided documents\n        averaged.\n        Parameters\n        ----------\n        doc_ids: List of int, str\n            Unique ids of document. If ids were not given, the index of\n            document in the original corpus.\n        doc_ids_neg: (Optional) List of int, str\n            Unique ids of document. If ids were not given, the index of\n            document in the original corpus.\n        num_docs: int\n            Number of documents to return.\n        return_documents: bool (Optional default True)\n            Determines if the documents will be returned. If they were not\n            saved in the model they will also not be returned.\n        use_index: bool (Optional default False)\n            If index_documents method has been called, setting this to True\n            will speed up search for models with large number of documents.\n        ef: int (Optional default None)\n            Higher ef leads to more accurate but slower search. This value\n            must be higher than num_docs.\n            For more information see:\n            https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md\n        Returns\n        -------\n        documents: (Optional) array of str, shape(num_docs)\n            The documents in a list, the most similar are first.\n            Will only be returned if the documents were saved and if\n            return_documents is set to True.\n        doc_scores: array of float, shape(num_docs)\n            Semantic similarity of document to keywords. The cosine similarity\n            of the document and average of keyword vectors.\n        doc_ids: array of int, shape(num_docs)\n            Unique ids of documents. If ids were not given to the model, the\n            index of the document in the model will be returned.\n        \"\"\"\n        if doc_ids_neg is None:\n            doc_ids_neg = []\n\n        self._validate_num_docs(num_docs)\n        self._validate_doc_ids(doc_ids, doc_ids_neg)\n\n        doc_indexes = self._get_document_indexes(doc_ids)\n        doc_indexes_neg = self._get_document_indexes(doc_ids_neg)\n\n        if use_index:\n            self._check_document_index_status()\n            document_vectors = self.document_vectors\n            doc_vecs = [document_vectors[ind] for ind in doc_indexes]\n            doc_vecs_neg = [document_vectors[ind] for ind in doc_indexes_neg]\n            combined_vector = self._get_combined_vec(doc_vecs, doc_vecs_neg)\n            return self.search_documents_by_vector(combined_vector, num_docs, return_documents=return_documents,\n                                                   use_index=True, ef=ef)\n\n        if self.embedding_model == 'doc2vec':\n            sim_docs = self.model.docvecs.most_similar(positive=doc_indexes,\n                                                       negative=doc_indexes_neg,\n                                                       topn=num_docs)\n            doc_indexes = [doc[0] for doc in sim_docs]\n            doc_scores = np.array([doc[1] for doc in sim_docs])\n        else:\n            doc_vecs = [self.document_vectors[ind] for ind in doc_indexes]\n            doc_vecs_neg = [self.document_vectors[ind] for ind in doc_indexes_neg]\n            combined_vector = self._get_combined_vec(doc_vecs, doc_vecs_neg)\n\n            num_res = min(num_docs + len(doc_indexes) + len(doc_indexes_neg),\n                          self.document_vectors.shape[0])\n\n            # don't return documents that were searched\n            search_doc_indexes = list(doc_indexes) + list(doc_indexes_neg)\n            doc_indexes, doc_scores = self._search_vectors_by_vector(self.document_vectors,\n                                                                     combined_vector, num_res)\n            res_indexes = [index for index, doc_ind in enumerate(doc_indexes)\n                           if doc_ind not in search_doc_indexes][:num_docs]\n            doc_indexes = doc_indexes[res_indexes]\n            doc_scores = doc_scores[res_indexes]\n\n        doc_ids = self._get_document_ids(doc_indexes)\n\n        if self.documents is not None and return_documents:\n            documents = self.documents[doc_indexes]\n            return documents, doc_scores, doc_ids\n        else:\n            return doc_scores, doc_ids\n\n    def generate_topic_wordcloud(self, topic_num, background_color=\"black\", reduced=False):\n        \"\"\"\n        Create a word cloud for a topic.\n        A word cloud will be generated and displayed. The most semantically\n        similar words to the topic will have the largest size, less similar\n        words will be smaller. The size is determined using the cosine distance\n        of the word vectors from the topic vector.\n        Parameters\n        ----------\n        topic_num: int\n            The topic number to search.\n        background_color : str (Optional, default='white')\n            Background color for the word cloud image. Suggested options are:\n                * white\n                * black\n        reduced: bool (Optional, default False)\n            Original topics are used by default. If True the\n            reduced topics will be used.\n        Returns\n        -------\n        A matplotlib plot of the word cloud with the topic number will be\n        displayed.\n        \"\"\"\n\n        if reduced:\n            self._validate_hierarchical_reduction()\n            self._validate_topic_num(topic_num, reduced)\n            word_score_dict = dict(zip(self.topic_words_reduced[topic_num],\n                                       softmax(self.topic_word_scores_reduced[topic_num])))\n        else:\n            self._validate_topic_num(topic_num, reduced)\n            word_score_dict = dict(zip(self.topic_words[topic_num],\n                                       softmax(self.topic_word_scores[topic_num])))\n\n        plt.figure(figsize=(16, 4),\n                   dpi=200)\n        plt.axis(\"off\")\n        plt.imshow(\n            WordCloud(width=1600,\n                      height=400,\n                      background_color=background_color).generate_from_frequencies(word_score_dict))\n        plt.title(\"Topic \" + str(topic_num), loc='left', fontsize=25, pad=20)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:37:22.354733Z","iopub.execute_input":"2022-12-07T16:37:22.355225Z","iopub.status.idle":"2022-12-07T16:37:22.610749Z","shell.execute_reply.started":"2022-12-07T16:37:22.355195Z","shell.execute_reply":"2022-12-07T16:37:22.609749Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":"# Top2Vec in Tamil <a class=\"anchor\"  id=\"top2vec-tamil\"></a>\n[Go Back to Table of Contents](#TOC)","metadata":{}},{"cell_type":"markdown","source":"## Load data <a class=\"anchor\"  id=\"loaddata\"></a>\n[Go Back to Table of Contents](#TOC)","metadata":{}},{"cell_type":"code","source":"# tamil_data = pd.read_csv(\"../input/tamil-nlp/tamil_news_train.csv\")\ntamil_data = pd.read_csv(\"../input/tamil-news-classification-dataset-tamilmurasu/tamilmurasu_dataset.csv\")\ntamil_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:37:55.270968Z","iopub.execute_input":"2022-12-07T16:37:55.271310Z","iopub.status.idle":"2022-12-07T16:38:06.230203Z","shell.execute_reply.started":"2022-12-07T16:37:55.271285Z","shell.execute_reply":"2022-12-07T16:38:06.229089Z"},"trusted":true},"execution_count":89,"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"   news_id            news_date news_category  \\\n0        6  1/6/2011 2:45:49 PM        மர்மம்   \n1        9  1/6/2011 2:56:51 PM        மர்மம்   \n2       10  1/6/2011 3:02:00 PM       இந்தியா   \n3       11  1/6/2011 3:08:15 PM        மர்மம்   \n4       12  1/6/2011 3:09:20 PM        மர்மம்   \n\n                                          news_title  \\\n0  தூக்கில் தொங்கும் சேவல்கள் திருடர்களை காவு வாங...   \n1                பவுர்ணமி ஜாமத்தில் மாயமான கர்ப்பிணி   \n2  காமன்வெல்த் ஊழல்: சுரேஷ் கல்மாடியிடம் 102 கேள்...   \n3                            மச்சுபிச்சு மலை ரகசியம்   \n4                      ரத்த பலி வாங்கும் விபரீத ஆவி!   \n\n                                        news_article  \n0  நாலு ஆள் உயரம், முறுக்கு மீசை, கையில் வீச்சரிவ...  \n1  அமானுஷ்யமான சம்பவங்கள் நம்மை சுற்றி ஆங்காங்கே ...  \n2  காமன்வெல்த் போட்டி ஏற்பாட்டில் நடைபெற்ற முறைகே...  \n3  தென்அமெரிக்க நாடான பெருவில் காடுகள் மிகவும் பய...  \n4  கடந்த 18ம் தேதி சாயங்காலம்... அடைமழையை கிழித்த...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>news_id</th>\n      <th>news_date</th>\n      <th>news_category</th>\n      <th>news_title</th>\n      <th>news_article</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>1/6/2011 2:45:49 PM</td>\n      <td>மர்மம்</td>\n      <td>தூக்கில் தொங்கும் சேவல்கள் திருடர்களை காவு வாங...</td>\n      <td>நாலு ஆள் உயரம், முறுக்கு மீசை, கையில் வீச்சரிவ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>1/6/2011 2:56:51 PM</td>\n      <td>மர்மம்</td>\n      <td>பவுர்ணமி ஜாமத்தில் மாயமான கர்ப்பிணி</td>\n      <td>அமானுஷ்யமான சம்பவங்கள் நம்மை சுற்றி ஆங்காங்கே ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10</td>\n      <td>1/6/2011 3:02:00 PM</td>\n      <td>இந்தியா</td>\n      <td>காமன்வெல்த் ஊழல்: சுரேஷ் கல்மாடியிடம் 102 கேள்...</td>\n      <td>காமன்வெல்த் போட்டி ஏற்பாட்டில் நடைபெற்ற முறைகே...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11</td>\n      <td>1/6/2011 3:08:15 PM</td>\n      <td>மர்மம்</td>\n      <td>மச்சுபிச்சு மலை ரகசியம்</td>\n      <td>தென்அமெரிக்க நாடான பெருவில் காடுகள் மிகவும் பய...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12</td>\n      <td>1/6/2011 3:09:20 PM</td>\n      <td>மர்மம்</td>\n      <td>ரத்த பலி வாங்கும் விபரீத ஆவி!</td>\n      <td>கடந்த 18ம் தேதி சாயங்காலம்... அடைமழையை கிழித்த...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# documents = list(tamil_data.NewsInTamil)\ndocuments = list(tamil_data.news_article)\ntype(documents[0])","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:38:11.554673Z","iopub.execute_input":"2022-12-07T16:38:11.555633Z","iopub.status.idle":"2022-12-07T16:38:11.589532Z","shell.execute_reply.started":"2022-12-07T16:38:11.555595Z","shell.execute_reply":"2022-12-07T16:38:11.588516Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"str"},"metadata":{}}]},{"cell_type":"code","source":"documents = documents[0:5000]","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:38:14.755288Z","iopub.execute_input":"2022-12-07T16:38:14.755764Z","iopub.status.idle":"2022-12-07T16:38:14.763404Z","shell.execute_reply.started":"2022-12-07T16:38:14.755731Z","shell.execute_reply":"2022-12-07T16:38:14.762346Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"## Parameters <a class=\"anchor\"  id=\"parameters\"></a>\nEmbedding models, HDBSCAN and UMAP parameters\n\n[Go Back to Table of Contents](#TOC)","metadata":{}},{"cell_type":"markdown","source":"#### Embedding Models [Paths] <a class=\"anchor\"  id=\"embeddingmodels\"></a>\n[Go Back to Table of Contents](#TOC)","metadata":{}},{"cell_type":"code","source":"# embdng_path = 'https://huggingface.co/google/muril-base-cased'\nembdng_path = 'https://huggingface.co/google/muril-large-cased'\n# embdng_path = 'https://huggingface.co/ai4bharat/indic-bert'\n#embdng_path = 'https://huggingface.co/Helsinki-NLP/opus-mt-en-dra'","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:38:20.252260Z","iopub.execute_input":"2022-12-07T16:38:20.252599Z","iopub.status.idle":"2022-12-07T16:38:20.257099Z","shell.execute_reply.started":"2022-12-07T16:38:20.252574Z","shell.execute_reply":"2022-12-07T16:38:20.256218Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":"#### UMAP and HDBSCAN parameters <a class=\"anchor\"  id=\"umaphdbscan\"></a>\n[Go Back to Table of Contents](#TOC)","metadata":{}},{"cell_type":"code","source":"hdbscan_args = dict({'min_cluster_size':30, 'min_samples':5, 'metric':'euclidean', 'cluster_selection_method': 'eom'})\numap_args = dict({'n_neighbors':20, 'min_dist':0.2, 'n_components':20, 'metric':'euclidean'})","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:38:23.569994Z","iopub.execute_input":"2022-12-07T16:38:23.570345Z","iopub.status.idle":"2022-12-07T16:38:23.577890Z","shell.execute_reply.started":"2022-12-07T16:38:23.570319Z","shell.execute_reply":"2022-12-07T16:38:23.575950Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":"## Getting Topic Vectors <a class=\"anchor\"  id=\"topicveccall\"></a>\n[Go Back to Table of Contents](#TOC)","metadata":{}},{"cell_type":"code","source":"dstl = Top2Vec(documents,embedding_model_path = embdng_path,umap_args = umap_args, hdbscan_args = hdbscan_args,tokenizer = custom_tokenizer) #, use_embedding_model_tokenizer=True, tokenizer = tokenizer )","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:38:27.508431Z","iopub.execute_input":"2022-12-07T16:38:27.508769Z","iopub.status.idle":"2022-12-07T16:39:49.629051Z","shell.execute_reply.started":"2022-12-07T16:38:27.508744Z","shell.execute_reply":"2022-12-07T16:39:49.627866Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stderr","text":"2022-12-07 16:38:27,512 - top2vec - INFO - Pre-processing documents for training\n2022-12-07 16:38:35,126 - top2vec - INFO - Creating joint document/word embedding\n2022-12-07 16:39:22,362 - top2vec - INFO - Creating lower dimension embedding of documents\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"2022-12-07 16:39:49,360 - top2vec - INFO - Finding dense areas of documents\n2022-12-07 16:39:49,532 - top2vec - INFO - Finding topics\n","output_type":"stream"}]},{"cell_type":"code","source":"# len(documents)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T08:59:53.758058Z","iopub.execute_input":"2022-11-03T08:59:53.758406Z","iopub.status.idle":"2022-11-03T08:59:53.763989Z","shell.execute_reply.started":"2022-11-03T08:59:53.758375Z","shell.execute_reply":"2022-11-03T08:59:53.762568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dstl = Top2Vec(documents[:50],embedding_model = \"muril-large-cased\",embedding_model_path = None,tokenizer = None,use_embedding_model_tokenizer=True) #, use_embedding_model_tokenizer=True, tokenizer = tokenizer )","metadata":{"execution":{"iopub.status.busy":"2022-11-03T08:59:53.765674Z","iopub.execute_input":"2022-11-03T08:59:53.766068Z","iopub.status.idle":"2022-11-03T08:59:53.775420Z","shell.execute_reply.started":"2022-11-03T08:59:53.766035Z","shell.execute_reply":"2022-11-03T08:59:53.774483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# custom_tokenizer('அமைதியாக இருங்கள்')","metadata":{"execution":{"iopub.status.busy":"2022-11-03T08:59:53.777289Z","iopub.execute_input":"2022-11-03T08:59:53.777836Z","iopub.status.idle":"2022-11-03T08:59:53.787387Z","shell.execute_reply.started":"2022-11-03T08:59:53.777793Z","shell.execute_reply":"2022-11-03T08:59:53.786266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dstl.get_num_topics()","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:39:49.635530Z","iopub.execute_input":"2022-12-07T16:39:49.635924Z","iopub.status.idle":"2022-12-07T16:39:49.646366Z","shell.execute_reply.started":"2022-12-07T16:39:49.635888Z","shell.execute_reply":"2022-12-07T16:39:49.645434Z"},"trusted":true},"execution_count":95,"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"27"},"metadata":{}}]},{"cell_type":"code","source":"topic_words, word_scores, topic_nums = dstl.get_topics()","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:39:49.649977Z","iopub.execute_input":"2022-12-07T16:39:49.650524Z","iopub.status.idle":"2022-12-07T16:39:49.658602Z","shell.execute_reply.started":"2022-12-07T16:39:49.650489Z","shell.execute_reply":"2022-12-07T16:39:49.657614Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"len(topic_words[0])","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:39:49.663075Z","iopub.execute_input":"2022-12-07T16:39:49.663386Z","iopub.status.idle":"2022-12-07T16:39:49.674836Z","shell.execute_reply.started":"2022-12-07T16:39:49.663357Z","shell.execute_reply":"2022-12-07T16:39:49.673876Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"50"},"metadata":{}}]},{"cell_type":"code","source":"tamil_topic_words = []\nfor t in topic_words:\n    for w in t:\n        tamil_topic_words.append(w)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:42:31.086424Z","iopub.execute_input":"2022-12-07T16:42:31.086960Z","iopub.status.idle":"2022-12-07T16:42:31.094388Z","shell.execute_reply.started":"2022-12-07T16:42:31.086917Z","shell.execute_reply":"2022-12-07T16:42:31.093427Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"path = 'google/muril-base-cased'\n## Loading the model\nfrom transformers import AutoModel, AutoTokenizer\nimport torch\nword_tokenizer = AutoTokenizer.from_pretrained(path)\nword_model = AutoModel.from_pretrained(path,output_hidden_states=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:52:57.437573Z","iopub.execute_input":"2022-12-07T16:52:57.437930Z","iopub.status.idle":"2022-12-07T16:53:34.929538Z","shell.execute_reply.started":"2022-12-07T16:52:57.437902Z","shell.execute_reply":"2022-12-07T16:53:34.928599Z"},"trusted":true},"execution_count":110,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/206 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc86aec5f24a42f7b1b8fa05649d73b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"185573002ca349b58c5e57a614942785"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/3.02M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"629875042b8341cabfc8a77ee5e18096"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/113 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ce8639f829e4db68d02a83ed9268bd1"}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/909M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ed288424ef43f0be68a7404b1b8ee2"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"#Mean Pooling - Take attention mask into account for correct averaging\ndef mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\ndef create_word_embeddings(wrd):\n  input_encoded = word_tokenizer.encode_plus(wrd, return_tensors=\"pt\")\n  with torch.no_grad():\n      states = word_model(**input_encoded).hidden_states\n  word_embeddings = mean_pooling(states, input_encoded['attention_mask'])\n  return(word_embeddings)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:53:34.931164Z","iopub.execute_input":"2022-12-07T16:53:34.931750Z","iopub.status.idle":"2022-12-07T16:53:34.939686Z","shell.execute_reply.started":"2022-12-07T16:53:34.931720Z","shell.execute_reply":"2022-12-07T16:53:34.938771Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"def get_topic_embeddings(wrds_list):\n    embdngs = np.zeros((len(wrds_list),768))\n    for w in range(len(wrds_list)):\n        embdngs[w,:] = create_word_embeddings(wrds_list[w]).numpy()\n    return(embdngs)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:58:16.698136Z","iopub.execute_input":"2022-12-07T16:58:16.698513Z","iopub.status.idle":"2022-12-07T16:58:16.704557Z","shell.execute_reply.started":"2022-12-07T16:58:16.698483Z","shell.execute_reply":"2022-12-07T16:58:16.703039Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"embdngs = get_topic_embeddings(tamil_topic_words)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:58:30.400899Z","iopub.execute_input":"2022-12-07T16:58:30.401315Z","iopub.status.idle":"2022-12-07T16:59:15.877499Z","shell.execute_reply.started":"2022-12-07T16:58:30.401285Z","shell.execute_reply":"2022-12-07T16:59:15.876396Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"embdngs.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:59:15.879609Z","iopub.execute_input":"2022-12-07T16:59:15.879960Z","iopub.status.idle":"2022-12-07T16:59:15.886144Z","shell.execute_reply.started":"2022-12-07T16:59:15.879928Z","shell.execute_reply":"2022-12-07T16:59:15.885352Z"},"trusted":true},"execution_count":128,"outputs":[{"execution_count":128,"output_type":"execute_result","data":{"text/plain":"(1350, 768)"},"metadata":{}}]},{"cell_type":"code","source":"# #np.save('tamil_topic_embdngs.npy')\n# embdngs = np.load('/kaggle/input/tamil-topic-embeddings/tamil_topic_embdngs.npy')\n# print(embdngs.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T15:33:20.939495Z","iopub.execute_input":"2022-12-07T15:33:20.940666Z","iopub.status.idle":"2022-12-07T15:33:20.951109Z","shell.execute_reply.started":"2022-12-07T15:33:20.940618Z","shell.execute_reply":"2022-12-07T15:33:20.950159Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(1700, 768)\n","output_type":"stream"}]},{"cell_type":"code","source":"import umap\nreducer = umap.UMAP()","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:59:15.887409Z","iopub.execute_input":"2022-12-07T16:59:15.887893Z","iopub.status.idle":"2022-12-07T16:59:15.897772Z","shell.execute_reply.started":"2022-12-07T16:59:15.887861Z","shell.execute_reply":"2022-12-07T16:59:15.896363Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"embedding = reducer.fit_transform(embdngs)\nembedding.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:59:15.902643Z","iopub.execute_input":"2022-12-07T16:59:15.903768Z","iopub.status.idle":"2022-12-07T16:59:20.550261Z","shell.execute_reply.started":"2022-12-07T16:59:15.903715Z","shell.execute_reply":"2022-12-07T16:59:20.548740Z"},"trusted":true},"execution_count":130,"outputs":[{"execution_count":130,"output_type":"execute_result","data":{"text/plain":"(1350, 2)"},"metadata":{}}]},{"cell_type":"code","source":"from scipy import spatial","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:59:20.551903Z","iopub.execute_input":"2022-12-07T16:59:20.552324Z","iopub.status.idle":"2022-12-07T16:59:20.558680Z","shell.execute_reply.started":"2022-12-07T16:59:20.552281Z","shell.execute_reply":"2022-12-07T16:59:20.557326Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"def get_outliers(embedding,tamil_topic_words):\n    n = len(tamil_topic_words)\n    cs_scores = np.zeros((n,n))\n    for i in range(n):\n        for j in range(n):\n            cs_scores[i][j] = 1 - spatial.distance.cosine(embedding[i], embedding[j])\n            \n    cs_thrs_1 = []\n    for j in range(0,n):\n        th1 = np.where(cs_scores[j,:] == 1)[0]\n        lmt = list(range(j*50,(j+1)*50))\n        cs_thrs_1.append([s for s in th1[1:] if s not in lmt])\n        \n    out_id = [o for c in cs_thrs_1 for o in c]\n    out_id = list(set(out_id))\n    \n    tamil_outliers = [tamil_topic_words[t] for t in out_id]\n    return(tamil_outliers,out_id)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T17:02:28.823203Z","iopub.execute_input":"2022-12-07T17:02:28.824366Z","iopub.status.idle":"2022-12-07T17:02:28.834796Z","shell.execute_reply.started":"2022-12-07T17:02:28.824325Z","shell.execute_reply":"2022-12-07T17:02:28.833559Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"tamil_outliers,out_id = get_outliers(embedding,tamil_topic_words)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T17:03:38.320379Z","iopub.execute_input":"2022-12-07T17:03:38.320787Z","iopub.status.idle":"2022-12-07T17:04:52.000639Z","shell.execute_reply.started":"2022-12-07T17:03:38.320755Z","shell.execute_reply":"2022-12-07T17:04:51.999581Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"get_outliers(embedding[:100,:],tamil_topic_words[:100])","metadata":{"execution":{"iopub.status.busy":"2022-12-07T17:02:58.761742Z","iopub.execute_input":"2022-12-07T17:02:58.762445Z","iopub.status.idle":"2022-12-07T17:02:59.181830Z","shell.execute_reply.started":"2022-12-07T17:02:58.762410Z","shell.execute_reply":"2022-12-07T17:02:59.180059Z"},"trusted":true},"execution_count":133,"outputs":[{"execution_count":133,"output_type":"execute_result","data":{"text/plain":"(['ரன்கள்', 'காலிறுதி', 'கைது', 'ரன்', 'வைத்தனர்'], [73, 75, 45, 89, 25])"},"metadata":{}}]},{"cell_type":"code","source":"print(len(tamil_outliers))","metadata":{"execution":{"iopub.status.busy":"2022-12-07T17:04:52.002414Z","iopub.execute_input":"2022-12-07T17:04:52.002757Z","iopub.status.idle":"2022-12-07T17:04:52.008306Z","shell.execute_reply.started":"2022-12-07T17:04:52.002724Z","shell.execute_reply":"2022-12-07T17:04:52.007102Z"},"trusted":true},"execution_count":135,"outputs":[{"name":"stdout","text":"528\n","output_type":"stream"}]},{"cell_type":"code","source":"c = []\nfor j in range(0,34):\n    c.append([j]*50)\ncolor = [j for i in c for j in i]","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:13:43.284504Z","iopub.execute_input":"2022-12-07T16:13:43.284867Z","iopub.status.idle":"2022-12-07T16:13:43.290259Z","shell.execute_reply.started":"2022-12-07T16:13:43.284821Z","shell.execute_reply":"2022-12-07T16:13:43.289117Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"outlier_color = []\nfor c in color:\n    if c in out_id:\n        outlier_color.append(100)\n    else:\n        outlier_color.append(c)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:44:06.077707Z","iopub.execute_input":"2022-12-07T16:44:06.078076Z","iopub.status.idle":"2022-12-07T16:44:06.208639Z","shell.execute_reply.started":"2022-12-07T16:44:06.078047Z","shell.execute_reply":"2022-12-07T16:44:06.206919Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"plt.scatter(\n    embedding[:, 0],\n    embedding[:, 1], c=outlier_color,cmap='Spectral',s=5)\nplt.gca().set_aspect('equal', 'datalim')\nplt.colorbar(boundaries=np.arange(35)).set_ticks(np.arange(35))\nplt.title('UMAP projection of Tamil Topic Words', fontsize=24)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T16:44:22.504034Z","iopub.execute_input":"2022-12-07T16:44:22.505279Z","iopub.status.idle":"2022-12-07T16:44:22.942410Z","shell.execute_reply.started":"2022-12-07T16:44:22.505237Z","shell.execute_reply":"2022-12-07T16:44:22.941272Z"},"trusted":true},"execution_count":105,"outputs":[{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"Text(0.5, 1.0, 'UMAP projection of Tamil Topic Words')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"## Embeddings \ntext = \"ஆந்திராவில்\"\nprint(create_word_embeddings(text).shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T11:06:38.542846Z","iopub.execute_input":"2022-12-07T11:06:38.544231Z","iopub.status.idle":"2022-12-07T11:06:38.657063Z","shell.execute_reply.started":"2022-12-07T11:06:38.544149Z","shell.execute_reply":"2022-12-07T11:06:38.655539Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"torch.Size([1, 768])\n","output_type":"stream"}]},{"cell_type":"code","source":"topic_word_embdngs = []\nfor t in topic_words:\n    topic_word_embdngs.append(get_topic_embeddings(t))","metadata":{"execution":{"iopub.status.busy":"2022-12-07T11:09:59.426874Z","iopub.execute_input":"2022-12-07T11:09:59.427365Z","iopub.status.idle":"2022-12-07T11:11:16.880210Z","shell.execute_reply.started":"2022-12-07T11:09:59.427324Z","shell.execute_reply":"2022-12-07T11:11:16.879035Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"topic_word_embdngs[0][0].shape","metadata":{"execution":{"iopub.status.busy":"2022-12-07T11:14:26.331415Z","iopub.execute_input":"2022-12-07T11:14:26.331910Z","iopub.status.idle":"2022-12-07T11:14:26.343381Z","shell.execute_reply.started":"2022-12-07T11:14:26.331873Z","shell.execute_reply":"2022-12-07T11:14:26.341744Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 768])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-12-07T11:25:18.848339Z","iopub.execute_input":"2022-12-07T11:25:18.848885Z","iopub.status.idle":"2022-12-07T11:25:23.815507Z","shell.execute_reply.started":"2022-12-07T11:25:18.848844Z","shell.execute_reply":"2022-12-07T11:25:23.813864Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"embdngs.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-07T11:25:27.795060Z","iopub.execute_input":"2022-12-07T11:25:27.796006Z","iopub.status.idle":"2022-12-07T11:25:27.808714Z","shell.execute_reply.started":"2022-12-07T11:25:27.795933Z","shell.execute_reply":"2022-12-07T11:25:27.807067Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"(1700, 768)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}